{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60dbba-78c2-4cc6-9bf8-0f33b2354841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8840800-b001-4470-9092-67081e6f06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что делает ИИ-агент?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac47304d-f5ce-43c8-b95e-9657067d30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Отвечает только на вопросы\n",
    "Выполняет команды по строгому сценарию\n",
    "Самостоятельно принимает решения и действует  #\n",
    "Только переводит текст\n",
    "Устанавливает обновления"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfc8d0f-8714-4eea-a004-ccffdc3169cf",
   "metadata": {},
   "source": [
    "ИИ-агент — это система, которая самостоятельно принимает решения и выбирает, что делать дальше, а не просто следует командам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438131d-5c62-4d44-b931-1b400c5973a0",
   "metadata": {},
   "source": [
    "ИИ-агент — это не просто модель, которая отвечает на вопрос. Это система, которая понимает задачу, решает, что нужно сделать, и действует самостоятельно. У неё есть инструменты (например, поиск в интернете), память (она может помнить, что было сказано ранее), и она сама выбирает последовательность шагов. Например, агент может сначала задать человеку вопрос, потом найти информацию в интернете, а затем выдать результат. Это уже похоже на поведение человека-помощника."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc6cb6-1e49-4cc1-9584-407ea4dbaa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2822753-5b59-4ef7-b8c2-9c121f2169d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "В чём отличие агента от обычного чат-бота?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafcd581-029b-4e41-a3ae-244298b022b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Агент всегда говорит по-английски\n",
    "Агент может использовать инструменты и действовать #\n",
    "Чат-бот умнее\n",
    "У агента нет интерфейса\n",
    "Агент работает только в браузере"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee6398b-be6e-4f4f-9aee-83afdf915eb1",
   "metadata": {},
   "source": [
    "В отличие от чат-бота, агент может использовать инструменты — например, делать поиск в интернете или задавать вопросы человеку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf56f4d-d3cd-4475-a044-10d7b0c194a5",
   "metadata": {},
   "source": [
    "Обычный чат-бот — это модель, которая отвечает на сообщения. Он может быть очень умным, но он не действует: он не делает запросы в интернет, не управляет логикой и не отслеживает, что уже сделано. Агенты могут использовать инструменты: запускать поиск, собирать данные, вести диалог по частям, проверять, достаточно ли информации. Это делает их намного ближе к «умному помощнику», чем к просто болтливому боту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c182773-857a-42de-9f1f-a37c98c17bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb533912-9fca-49fa-bd28-4801eb2fd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что из этого является примером инструмента для ИИ-агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36425c14-e574-4b19-af5b-0d3429623bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Word и Excel\n",
    "Google Search API #\n",
    "TikTok\n",
    "Discord чат\n",
    "Zoom-звонок"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1c445-ff71-4b4c-9897-d029027c751b",
   "metadata": {},
   "source": [
    "Инструменты для ИИ-агента — это функции, с помощью которых он может получать данные или выполнять действия. Поиск в интернете — классический пример."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2094a6d-bfc4-4194-a7e4-0a4cf8570d0c",
   "metadata": {},
   "source": [
    "Агент сам не может напрямую заходить в интернет или взаимодействовать с пользователем — он «просит» кого-то это сделать. Инструменты (tools) — это мост между агентом и внешним миром. Например, если агенту нужно узнать адрес компании, он может использовать Google Search API. Если надо задать вопрос человеку — применяется human_input_tool. Эти инструменты запускаются по запросу агента и возвращают ему результат, который он затем анализирует."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5419b5a-a1fa-40b4-9bcb-cc96713420ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192db39-df5d-4d1b-b44f-b3a41a3674c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что из этого не является примером инструмента для ИИ-агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a023740-67f0-45d9-b766-e559b60e05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleSearchTool — поиск информации в интернете\n",
    "HumanInputTool — запрос данных у пользователя\n",
    "MathTool — вычисления\n",
    "EmailSender — отправка писем\n",
    "ChatGPT — генерация текста  #\n",
    "WeatherAPI — получение прогноза погоды"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625e6f93-d9bd-4b32-8ffd-fcf018ddaa32",
   "metadata": {},
   "source": [
    "ChatGPT — это сама языковая модель, а не инструмент. Инструменты — это внешние функции, к которым LLM обращается для действий вне своего текста."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f461f6d-629a-4832-9193-98ba069f475f",
   "metadata": {},
   "source": [
    "Инструменты (tools) — это внешние функции, которые агент вызывает, когда нужно выполнить действие вне LLM: найти информацию, задать вопрос, отправить письмо и т.д. Например, GoogleSearchTool запускает поиск, HumanInputTool позволяет задать вопрос человеку, а EmailSender — отправить письмо. Но ChatGPT — это сама языковая модель, основа агента. Она не является инструментом, а скорее «мозгом» агента. Инструменты — это его «руки» и «глаза», но не сам разум. Поэтому именно ChatGPT — неверный ответ в списке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a433004-f9c7-4311-8a0d-d71e7ccc5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324019b7-513d-4f5d-b8dc-49d32719cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что хранит “состояние” агента (state)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66536e3-e605-43e7-9e68-f0042671e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "Пароли пользователей\n",
    "Историю переписки и промежуточные результаты #\n",
    "Только список IP-адресов\n",
    "Данные банковской карты\n",
    "Ничего"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a6f00-142c-44e3-9c44-3b1f4a3d313d",
   "metadata": {},
   "source": [
    "Состояние агента — это всё, что он помнит: переписка, собранные данные, результаты инструментов. Без этого он не сможет работать как помощник."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48662b04-bb30-402d-8d7d-f5a13533b946",
   "metadata": {},
   "source": [
    "Когда агент работает, он должен помнить, что уже было сказано, какие данные получены и какие действия уже выполнены. Это называется состоянием (state). Оно может включать сообщения пользователя и LLM, вызовы инструментов, текущие цели и собранную информацию. Благодаря состоянию агент не повторяет себя и может строить логичную стратегию — как настоящий помощник."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42815785-e547-443c-9861-848ac57197c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8487f2-ad2b-4a32-afd5-aae595739fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Когда агент завершает свою работу?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbe0fb7-d889-4954-a1b4-b1f83e0f9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Когда закончатся токены\n",
    "B. Когда получит все нужные данные #\n",
    "C. Когда прервётся интернет\n",
    "D. Когда ему скучно\n",
    "E. Всегда через 10 минут"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c59b8-ae2f-4a32-9587-f4e6017e1259",
   "metadata": {},
   "source": [
    "Агент завершает работу тогда, когда считает, что задача решена — например, все данные собраны и финальный результат готов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c74ccd1-432f-4499-b4ff-992b850eba25",
   "metadata": {},
   "source": [
    "Один из ключевых принципов агента — он работает, пока не достигнет цели. В простом случае это может быть: “собрать все данные”. Агент использует инструменты, задаёт вопросы, делает выводы. Когда всё готово — он возвращает результат и завершает работу. При этом он сам решает, что \"всё готово\", на основе логики или условий в коде. Это делает поведение агента более гибким и автономным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ff66a-08c2-4a50-8667-a61d00f34e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2f372-bce4-4001-b9d8-6f765cee90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что делает ИИ-агент, если ему не хватает данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f09e90-62de-4a21-9119-68714e54ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Завершает работу с ошибкой\n",
    "Запрашивает недостающие данные с помощью инструментов  #\n",
    "Переходит в спящий режим\n",
    "Начинает заново с первого шага\n",
    "Ничего не делает"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2aa216-7f7e-4493-85e7-e43e4e3fa014",
   "metadata": {},
   "source": [
    "Если агенту не хватает данных, он может использовать инструменты — например, задать вопрос человеку или сделать повторный поиск."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf941ab-ad53-43cc-bf81-ab22ed40c24a",
   "metadata": {},
   "source": [
    "ИИ-агент умеет действовать по ситуации. Если он обнаруживает, что для выполнения задачи ему не хватает информации (например, отсутствует дата покупки), он может использовать инструменты: сделать запрос к пользователю (через human tool) или выполнить дополнительный поиск (search tool). Это делает агента гибким и способным работать в условиях неопределённости — как настоящий помощник."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fc40e-cc2a-4ae9-bd1b-908f3010420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f6017-4000-4114-ae14-b570cdaf15f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что из этого не является обязательным элементом ИИ-агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe71195-1355-4d16-ba00-87cbb78bdbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Языковая модель (LLM)\n",
    "Инструменты (tools)\n",
    "Состояние (state)\n",
    "Граф управления (workflow)\n",
    "Графический интерфейс  #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df4351-8450-43b2-95de-5929669b6702",
   "metadata": {},
   "source": [
    "ИИ-агент может работать без интерфейса — он нужен только для удобства. А вот LLM, инструменты и логика переходов обязательны."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a3724-42e7-4478-9f5d-b370c27184b4",
   "metadata": {},
   "source": [
    "Графический интерфейс (GUI) может сделать работу агента более наглядной, но он не является обязательной частью системы. Важно, чтобы у агента были: языковая модель (для принятия решений и генерации текста), инструменты (для действий), состояние (для памяти) и логика переходов (граф, например, в LangGraph). Даже в консоли агент будет работать — главное, чтобы у него была логика и доступ к нужным действиям.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3784703-94ab-495b-acfa-56947aa74ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94943f62-249a-478e-a65b-ab3ad1af0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что главное отличает ИИ-агента от просто запроса к LLM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa592d04-9445-495c-994b-a0c341cefc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Агент тратит меньше токенов\n",
    "B. Агент сам выбирает, что делать дальше  #\n",
    "C. Агент не может писать текст\n",
    "D. Агент работает только в Chrome\n",
    "E. Агент не использует память"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06946b79-4943-4b52-b319-7efcab8ca9f5",
   "metadata": {},
   "source": [
    "ИИ-агент умеет принимать решения и сам выбирает, какое действие предпринять: задать вопрос, поискать, завершить работу и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad1461-295f-49b4-8842-10ea06d799b3",
   "metadata": {},
   "source": [
    "Когда мы просто отправляем запрос в ChatGPT, модель отвечает, не принимая решений о действиях. ИИ-агент — это система, в которой LLM не просто отвечает, а управляет логикой: \"мне не хватает данных → я спрошу человека\", \"у меня есть tool_call → я попрошу вызвать инструмент\", \"всё готово → я завершу\". Это автономия в мышлении и действии — ключевой признак агента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25df3a-18fa-4d8b-a2dc-ebcc8056c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e60e766-c102-4a42-b62e-ad08d6dec527",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что из этого может быть хорошим применением ИИ-агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b4dfe-5c8c-4a73-9b7f-27a29ac5b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "Запись песни\n",
    "Подбор одежды по фотографии\n",
    "Автоматический сбор данных перед подачей жалобы  #\n",
    "Скачивание фильмов\n",
    "Переименование файлов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feb3b68-a0d3-4ed1-893f-fe3841af8be1",
   "metadata": {},
   "source": [
    "Агент идеально подходит для задач, где нужно собрать информацию из разных источников, задать уточняющие вопросы и подготовить результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d0d75-3b6a-4ad8-9772-03ba47f30dfb",
   "metadata": {},
   "source": [
    "ИИ-агенты отлично работают в задачах, где есть несколько этапов, неопределённость и необходимость адаптироваться. Сбор данных для юриста — классический пример: нужно понять, что уже есть, чего не хватает, спросить клиента, найти недостающее и выдать результат. Агент может справиться с этим сам, экономя время специалиста и повышая эффективность бизнеса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21893231-1b94-4194-a435-f99d9ed53929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3755b8-08fb-4749-a51a-f28c7d3a4cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что из этого не может быть хорошим применением ИИ-агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ebbdb2-613a-4905-a20f-d18aa7e96b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Автоматический помощник юриста, собирающий данные у клиента\n",
    "B. Агент, бронирующий отели и перелёты по заданным критериям\n",
    "C. Агент, который ищет статьи закона по теме запроса\n",
    "D. Агент, просматривающий фильмы и ставящий им оценки  #\n",
    "E. Агент, который помогает заполнять налоговые формы\n",
    "F. Агент, подбирающий вакансии и отправляющий резюме"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22532fa7-efcc-40fe-88c7-1d07502e83d4",
   "metadata": {},
   "source": [
    "ИИ-агенты отлично работают с задачами, где нужно собирать, анализировать и структурировать информацию. Но просмотр фильмов и выставление оценок — это субъективный и визуальный процесс, не подходящий для LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b55ffb6-2789-4d55-a9c6-9c07dff63e54",
   "metadata": {},
   "source": [
    "ИИ-агенты — это автономные системы, способные выполнять задачи с использованием текста, API, диалога и логики. Они хорошо справляются с работой, где нужно собрать данные, задать уточняющие вопросы, сделать поиск и подготовить результат. Но просмотр фильмов — это визуальная задача, требующая восприятия видеоряда, эмоций, субъективных вкусов. LLM пока не могут «смотреть» фильмы, а оценки без восприятия — это фикция. Такая задача выходит за пределы возможностей текущих текстовых ИИ. Поэтому это плохое применение агента.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745ee7c-77b3-4f85-9f36-b1926c084310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c376b83-fd0c-4895-9ec2-2f4e7a55246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что будет, если агенту не объяснить, как использовать инструменты?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903f2e0-8ec1-45ee-9679-99657f802042",
   "metadata": {},
   "outputs": [],
   "source": [
    "Он сам догадается\n",
    "Он будет бесконечно думать\n",
    "Он будет просить всё у человека #\n",
    "Он отключится от сервера\n",
    "Он удалит всю переписку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423a298-8d67-4a8a-8deb-1e0607e0c5b0",
   "metadata": {},
   "source": [
    "Если LLM не знает, как использовать инструменты, он \"ленится\" и будет просто спрашивать всё у человека."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a35768-c0a1-4f5d-9035-365be554a1c0",
   "metadata": {},
   "source": [
    "Без чёткой инструкции (в системном промпте), LLM может не использовать инструменты и пойти по пути наименьшего сопротивления: просто задаст человеку длинный список вопросов. Это снижает эффективность агента. Чтобы избежать этого, важно заранее объяснить, какие есть инструменты и как ими пользоваться. Например: \"Для поиска информации используй Tavily. Для общения — HumanTool. Собирай данные по шагам.\" Это основа промпт-инжиниринга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e59a34b-41f7-444b-b274-45239f4a6ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a490241-0798-4c2b-8431-ab0d1112d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "Какой из этих агентов, скорее всего, не сможет эффективно работать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3248f3b7-a250-4a31-a7f9-c6fe37caf0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Агент, собирающий контактные данные компаний из открытых источников\n",
    "Агент, уточняющий у клиента недостающие паспортные данные\n",
    "Агент, который звонит по телефону и ведёт разговор голосом  #\n",
    "Агент, помогающий заполнить анкету на визу\n",
    "Агент, ищущий юридические данные по ИНН через API\n",
    "Агент, составляющий черновик жалобы по шаблону"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68f9a9-d68a-4ac0-8ac4-3a35b8237fa8",
   "metadata": {},
   "source": [
    "Большинство ИИ-агентов работают в текстовом формате. Телефонный звонок с голосом и распознаванием речи требует других технологий, которые обычные LLM не поддерживают."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd733fe-ea63-4678-a0a5-6a3fcb129ce6",
   "metadata": {},
   "source": [
    "ИИ-агенты обычно работают в текстовом пространстве: они читают и пишут текст, обрабатывают структурированные данные, делают запросы к API. Некоторые агенты могут использовать внешние голосовые интерфейсы, но сам по себе LLM — это не голосовой помощник. Чтобы агент мог звонить и вести разговор, нужна интеграция с системами распознавания речи (ASR) и синтеза речи (TTS), а также управление реальным временем диалога. Без этого LLM просто не сможет вести телефонный разговор. Это технически возможно, но выходит за рамки “типичного” текстового агента — значит, такой агент работать «в чистом виде» не сможет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6cc27e-e72c-403f-9575-5e93902d80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209cef4-b0c9-4fb6-8045-10fe9ba6d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Когда ИИ-агенту нельзя полностью доверять решение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a40df3d-46dd-4198-b8fd-562cdc5e2254",
   "metadata": {},
   "outputs": [],
   "source": [
    "Когда задача чёткая и одношаговая\n",
    "Когда агент использует поиск\n",
    "Когда задача требует юридической ответственности  #\n",
    "Когда агент работает без инструментов\n",
    "Когда агент получил все данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51499f-d5cf-4783-95fa-ab082f297f7c",
   "metadata": {},
   "source": [
    "Агенты могут помогать, но не должны принимать решения в юридических, медицинских и других критически важных сферах без проверки человеком."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29490f32-8656-4e82-b1a0-f7b647963862",
   "metadata": {},
   "source": [
    "ИИ-агенты — мощные помощники, но они не имеют правового, медицинского или экспертного статуса. Даже если агент правильно собрал информацию и сгенерировал текст, его выводы не всегда точны или надёжны. Особенно в вопросах, где есть риски — юридических спорах, диагнозах, финансах — ИИ может ошибиться или интерпретировать информацию некорректно. В таких случаях важно, чтобы финальное решение принимал человек-специалист."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f040382-05d7-4c4d-850f-4882e38cf897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5135dae9-30fd-4aea-aff9-75ec407f603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что ИИ-агент не может делать без подключения к API или внешним инструментам?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b9f71-3c4b-41b6-b344-af25f6bb23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Сохранять историю сообщений\n",
    "Генерировать текст на заданную тему\n",
    "Искать свежую информацию в интернете  #\n",
    "Писать JSON\n",
    "Задавать уточняющие вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ba247-5c2a-4cf9-a02d-70a43dc99690",
   "metadata": {},
   "source": [
    "Без подключения к поисковым API или базам данных агент не может получать свежую информацию, он работает только с тем, что уже знает."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88930eb-4403-48cb-a8b9-0dc079df9241",
   "metadata": {},
   "source": [
    "LLM, как основа агента, обучается на данных до определённой даты и не имеет встроенного интернета. Чтобы получить актуальные данные (например, адрес компании или курс валют), агент должен использовать API поиска (например, Tavily, Bing API и т.д.). Если такие инструменты не подключены, он может лишь «угадывать» или опираться на устаревшие данные из своей обучающей выборки. Это делает его неэффективным при работе с новостями, динамическими данными или конкретными запросами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3cddb-7514-461f-a6de-5e5583f044f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4201edc-7323-4c56-9747-bd082aad8dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Где ИИ-агенты ошибаются чаще всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9871f7d-8fa5-487f-9721-7f3d4a3963dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "В написании текста\n",
    "В логике выполнения многошаговых задач #\n",
    "В генерации простого списка\n",
    "В повторении вопроса\n",
    "В открытии файла"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1009d-647a-4548-938d-ad729ac3f64b",
   "metadata": {},
   "source": [
    "Агенты часто ошибаются в сложных сценариях, где нужно помнить контекст, планировать шаги и принимать решения по ситуации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e098b9d-0013-486a-81c8-16a489916a83",
   "metadata": {},
   "source": [
    "Хотя ИИ-агенты отлично справляются с отдельными действиями — например, сформулировать текст, сделать поиск или задать вопрос — они часто дают сбой в многошаговых сценариях. Например, могут забыть, что уже спрашивали у пользователя, повторить шаг, не заметить, что ещё не получили все нужные данные. Это связано с ограничениями памяти, неверной логикой или неправильной интерпретацией стейта. Поэтому особенно важно тщательно проектировать логику агента и предусматривать проверки на каждом шаге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0582878-7e47-4a4b-ac67-95cb6581ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a57ce-2ff2-41ad-918d-95a32b0b059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что такое LangGraph и зачем он нужен при создании ИИ-агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e07ca-d9e1-42b0-a52d-18f534705aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Это чат для общения с агентом\n",
    "B. Это библиотека для работы с голосом\n",
    "C. Это инструмент, позволяющий управлять шагами агента, как по схеме  #\n",
    "D. Это база данных для хранения паспортов\n",
    "E. Это приложение для визуализации JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0be7292-999d-40e8-b0be-fc6f617b2137",
   "metadata": {},
   "source": [
    "LangGraph — это библиотека, которая помогает выстраивать шаги работы ИИ-агента как схему: что делать сначала, что потом, когда повторить, когда остановиться."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1254b8-e556-4a50-873d-a2ac1cfbe16b",
   "metadata": {},
   "source": [
    "LangGraph — это библиотека, созданная специально для работы с ИИ-агентами. Она позволяет выстраивать поведение агента в виде графа — последовательности шагов, между которыми агент может переходить. Например: сначала агент обращается к LLM, затем проверяет, нужно ли использовать инструмент, затем вызывает поиск, снова обрабатывает результат и так далее. Это похоже на маршрут, по которому агент движется, принимая решения. LangGraph особенно удобен, если агент работает в несколько этапов и должен принимать решения в зависимости от результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7b7a8a-2664-4b31-9fba-c47f1d5fce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27f63d-4ae5-47be-aa23-d23517f1c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "Какую роль играет состояние (state) в ИИ-агенте на LangGraph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6fcb74-acc3-4dcb-bf4e-3cd08597a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Хранит историю команд shell\n",
    "Сохраняет результаты поиска, сообщений и действий  #\n",
    "Показывает статус работы Tavily\n",
    "Хранит только последний ответ LLM\n",
    "Управляет доступами к GPT API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2619baef-ef77-4c45-8c30-349e020cbe35",
   "metadata": {},
   "source": [
    "State — это хранилище всего контекста: сообщений, результатов инструментов и других переменных, доступных на всех этапах работы агента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29d8ec6-3820-44fe-93ce-c927a7b9ec66",
   "metadata": {},
   "source": [
    "Без состояния агент теряет память о предыдущих шагах. MessagesState — это контейнер, где хранятся все HumanMessage, SystemMessage, AIMessage, ToolCalls, ответы, и т.д. На каждом новом цикле LLM получает весь контекст, включая запросы, ответы и собранные данные. Это позволяет строить сложные цепочки взаимодействий и поддерживать логику агента на протяжении всей сессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28b03a-9ce2-4640-9c93-8f498c44984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa4965-dae2-40b6-918e-d197e4e9d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    " Что такое tool_calls в работе ИИ-агента?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a829f-de81-47d9-b040-362a5d96f6f6",
   "metadata": {},
   "source": [
    "Список команд для установки Python-библиотек\n",
    "Способ вызвать ChatGPT через браузер\n",
    "Инструкция от LLM о том, какой инструмент нужно использовать и с какими параметрами #\n",
    "Название функции для выхода из агента\n",
    "Ошибка в коде, когда нет интернета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21696db9-4dfc-444b-aa39-b056b1a1674b",
   "metadata": {},
   "source": [
    "tool_calls — это особый ответ от LLM, в котором она просит вызвать нужный инструмент: например, поиск, вопрос к человеку или работу с базой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2a782-b1d9-449f-b781-6004c204adf8",
   "metadata": {},
   "source": [
    "Когда ИИ-агент (на базе LLM) понимает, что ему нужен внешний инструмент — например, чтобы сделать поиск в интернете или задать вопрос человеку — он не вызывает его напрямую. Вместо этого он формирует специальный блок ответа — tool_calls, где указывает:\n",
    "какое действие нужно (название инструмента),\n",
    "какие параметры передать (например, поисковый запрос).\n",
    "LangGraph или другая платформа затем выполняет этот tool_call и возвращает результат LLM. Это делает агента похожим на человека: он говорит, что хочет сделать, а \"руки\" (инструменты) делают это за него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f825c-efba-4d80-a532-a607be7f4162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5db1e-7798-4e4c-ad70-e22fa191222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что происходит, когда LLM возвращает tool_calls во время работы агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d5dd0-0a97-4ae8-8ad0-5d162e098695",
   "metadata": {},
   "outputs": [],
   "source": [
    "Агент завершает работу и показывает результат\n",
    "B. Агент ждёт ответа от пользователя\n",
    "C. Агент просит разработчика вмешаться\n",
    "D. Агент передаёт вызовы в ToolNode, где запускаются нужные инструменты #\n",
    "E. Агент очищает память и начинает заново"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97558f7e-b741-49bf-ab0e-edac678f48f6",
   "metadata": {},
   "source": [
    "Если в ответе от LLM есть tool_calls, агент передаёт управление специальной ноде (ToolNode), которая выполняет эти вызовы: поиск, запрос, вычисления и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d946eae-3d8e-4892-8952-41710624d710",
   "metadata": {},
   "source": [
    "Когда LLM в ходе своей работы решает, что ей нужен внешний инструмент (например, Tavily для поиска), она возвращает в ответе специальный блок tool_calls. Это своего рода “запрос на действие”: указание, какой инструмент вызвать и с какими параметрами. LangGraph реагирует на это, передавая управление в ToolNode, где указанный инструмент действительно запускается. Полученный результат потом возвращается обратно LLM — и агент продолжает работу с учётом новой информации. Если tool_calls нет, агент может завершить выполнение или продолжить другой логикой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee12fb3-0b75-4c56-a287-0f66b81a7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b3504-5c5f-4042-9405-a0ebcd256d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что произойдёт, если tool_calls пустой, но в state ещё не хватает данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81a7e2-9c87-4379-9de0-a19f40e94240",
   "metadata": {},
   "outputs": [],
   "source": [
    "Агент автоматически вызывает Tavily\n",
    "B. Агент завершит работу, если не запрограммирована проверка полноты  #\n",
    "C. Агент сбросит state\n",
    "D. Агент перезагрузит модель\n",
    "E. Агент отправит запрос в OpenAI Support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2593da-9433-4a14-99e6-c12618f99388",
   "metadata": {},
   "source": [
    "По умолчанию агент завершает работу, если tool_calls нет, и не задана явная проверка «достаточно ли данных». Проверка полноты — это ответственность разработчика."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd0f97-4a61-4148-8d28-83ccacba7a0d",
   "metadata": {},
   "source": [
    "В LangGraph логика переходов строится вокруг tool_calls. Если их нет, и не задана дополнительная проверка (например, функция is_data_complete()), то агент считает, что задача завершена, и переходит к END. Это поведение нужно корректировать вручную — например, если вы хотите, чтобы агент продолжал работу, пока не соберёт все нужные поля, даже если LLM «считает», что задача решена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799c4ee-3a33-4d56-ac6b-d7d6b78dd226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139111f-f050-4e7f-855a-5e665c31920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что должен содержать каждый tool_call?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d3b3e-0db2-4937-95e8-4b924d03a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Только имя инструмента\n",
    "B. Только текст команды\n",
    "C. Название инструмента и аргументы (параметры для выполнения) #\n",
    "D. Список пользователей\n",
    "E. Текущий токен авторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b451090-d98c-4f43-8fea-ba33c5e862ef",
   "metadata": {},
   "source": [
    "tool_call включает имя инструмента (например, search) и аргументы, которые нужно передать (например, query: “адрес компании”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd12d8-c10b-4f30-8d64-f99f3b97869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"name\": \"search\",\n",
    "  \"args\": { \"query\": \"Worldclass юридический адрес\" }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e862a59c-2001-4d84-a9fc-40b3fbe19371",
   "metadata": {},
   "source": [
    "tool_call — это способ, с помощью которого языковая модель (LLM), действующая как агент, сообщает системе: “мне нужно выполнить внешнее действие”. Например, если агенту нужно найти информацию в интернете, он не делает это сам, а формирует специальную инструкцию — tool_call, в которой указывает, какой инструмент нужно использовать и с какими параметрами.\n",
    "\n",
    "Каждый tool_call обязательно должен содержать два ключевых элемента:\n",
    "\n",
    "Название инструмента — это уникальное имя, которое соответствует конкретной функции или внешнему действию. Например, это может быть search, get_weather, ask_user, и так далее. Это имя используется системой, чтобы понять, какой из подключённых инструментов нужно активировать.\n",
    "\n",
    "Аргументы — это данные, которые необходимы для выполнения действия. Они зависят от того, что делает инструмент. Например, если это поиск, нужен текст запроса; если это отправка сообщения, нужен адрес и содержание; если это калькулятор, нужны числа и операция. Без аргументов инструмент не сможет выполнить задачу правильно.\n",
    "\n",
    "Таким образом, tool_call — это не просто пожелание модели, это структурированная инструкция, которую агентная система должна точно распознать и исполнить. Если модель не укажет название инструмента или не добавит нужные параметры, вызов будет неполным или даже некорректным.\n",
    "\n",
    "Важно также, что инструменты, на которые LLM может ссылаться, должны быть заранее объявлены в конфигурации агента. Если модель попробует вызвать инструмент, которого нет в списке доступных, система не сможет выполнить его и вызов будет проигнорирован или вызовет ошибку.\n",
    "\n",
    "В итоге, tool_call — это мост между интеллектом модели и её способностью действовать во внешнем мире. Он превращает пассивное текстовое мышление в активное поведение: задавать вопросы, искать данные, принимать решения на основе внешней информации. И чтобы этот мост работал, он должен быть чётко оформлен — с названием инструмента и набором аргументов.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb0227-ade1-48e9-9575-78677af059c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9cc4c9-311c-4518-8dcf-2ad844d7bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что произойдёт, если LLM вернёт tool_call, но нужный инструмент не подключён к агенту?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238befd-6a20-4d30-910a-69968da195c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A. Инструмент создастся автоматически\n",
    "B. Агент переключится на другой инструмент\n",
    "C. Возникнет ошибка или игнорирование вызова  # \n",
    "D. Агент завершит работу\n",
    "E. Агент запросит логин пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f499557-d9f3-4dec-8c61-e6aa8f3a3b32",
   "metadata": {},
   "source": [
    "Если LLM запросит вызов инструмента, которого нет в tools, вызов не выполнится, и система может выдать ошибку или просто пропустить его."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e7c64-3026-4efa-94e2-75f3e2753e23",
   "metadata": {},
   "source": [
    "Для работы с инструментами агенту нужно заранее передать список доступных tools. Если LLM сгенерирует tool_call на инструмент, которого в этом списке нет, то LangGraph не сможет его вызвать. Такое поведение нужно обрабатывать: можно вывести сообщение об ошибке, залогировать проблему или обучить LLM не использовать несуществующие инструменты (например, через системный промпт)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a59629-61b4-4b25-8ce2-6f08c3c5315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3687fdab-db89-4cc4-bd2c-8942f28bd15e",
   "metadata": {},
   "source": [
    "Когда LLM возвращает tool_call, что ожидается от LangGraph или другой агентной системы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce73862-8887-4d89-a599-df1f7ed7eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Преобразовать tool_call в JSON и отправить его обратно пользователю\n",
    "Сохранить tool_call в лог-файл\n",
    "Выполнить инструмент и вернуть результат обратно в контекст LLM  #\n",
    "Остановить выполнение\n",
    "Перезапустить LLM с другим промптом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31eb8ae-66c3-49ee-a686-d5d2332e18fe",
   "metadata": {},
   "source": [
    "Когда приходит tool_call, агент вызывает нужный инструмент, получает результат и возвращает его в виде нового сообщения в историю, чтобы LLM продолжила."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26818bac-22fa-4766-9fa5-8c866171c980",
   "metadata": {},
   "source": [
    "Вся суть tool_call — дать LLM возможность “действовать”. Агентная система (например, LangGraph) берёт tool_call, запускает соответствующую функцию (поиск, диалог с пользователем и т.д.), получает результат и добавляет его в state. После этого gather_data_node вызывается снова — уже с новым знанием. Это позволяет агенту шаг за шагом собирать данные и принимать решения.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18588e67-983d-4f5e-9c40-8c29cf9874f5",
   "metadata": {},
   "source": [
    "Когда языковая модель (LLM), такая как GPT-4, работает в составе ИИ-агента, она действует не просто как генератор текста, а как участник более сложного процесса, в котором требуется не только \"говорить\", но и \"действовать\". Для того чтобы агент мог выполнять действия вне самого текста — например, искать информацию в интернете, задавать вопросы пользователю, выполнять вычисления или обращаться к базе данных — используются инструменты (tools).\n",
    "Но языковая модель сама по себе не может напрямую запускать никакие инструменты. Она может только сообщить системе о своём намерении: \"мне нужно, чтобы ты сейчас сделал вот это\". Это сообщение оформляется в виде tool_call — специальной структуры, которую модель возвращает вместо обычного текстового ответа.\n",
    "Что делает LangGraph или аналогичная система (например, LangChain Agents), когда получает tool_call?\n",
    "Она не трактует это как обычный текстовый ответ. Вместо этого она воспринимает tool_call как инструкцию к действию и берёт на себя задачу исполнения. То есть модель отдала \"команду\", а LangGraph превращает её в реальное выполнение.\n",
    "Система выполняет следующие шаги:\n",
    "Распознаёт, какой инструмент указан в tool_call — для этого в агент заранее передаётся список доступных инструментов.\n",
    "Находит этот инструмент в списке и проверяет, какие аргументы модель ему передала.\n",
    "Запускает инструмент с указанными параметрами — например, делает HTTP-запрос к поисковой системе, или показывает пользователю вопрос, или обращается к внутреннему API.\n",
    "Получает результат выполнения инструмента — это может быть текст, список данных, структурированная информация и т.п.\n",
    "Возвращает этот результат обратно в агент — но не напрямую в модель, а в виде нового сообщения, которое добавляется к состоянию (state), где хранятся все сообщения и действия.\n",
    "После этого агент снова вызывает LLM — уже с учётом обновлённого контекста. Модель \"видит\" результат вызова инструмента и может продолжать работу: интерпретировать его, делать выводы, переходить к следующему шагу или завершать выполнение, если задача решена.\n",
    "Таким образом, tool_call — это инициатор действия, а LangGraph — исполнитель и посредник между умной моделью и внешним миром. Именно LangGraph превращает намерения LLM в реальные действия, а потом возвращает информацию обратно в диалог.\n",
    "Без этого механизма агент был бы просто продвинутым чат-ботом. А с ним — становится настоящей автономной системой, способной взаимодействовать с внешним окружением: пользователем, интернетом, базами данных, API и даже физическим миром (если добавить роботов, датчики, голосовые модули и т.д.).\n",
    "Вот почему реакция на tool_call — ключевая часть архитектуры ИИ-агента. Она превращает \"интеллект в тексте\" в \"интеллект в действии\".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e707208-6026-4b25-a38f-0dcb4f9c93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173fa81-b976-43e1-91b0-6d318198f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что хранит MessagesState в ИИ-агенте?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa8d648-5fc0-41e9-bdcc-dc9d0dbb50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Настройки сети и версии модели\n",
    "Список команд разработчика\n",
    "Историю сообщений между LLM, пользователем и инструментами #\n",
    "Данные для входа в систему\n",
    "Только последний ответ LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4f9c6-f315-44d0-8bec-d92e0f31db53",
   "metadata": {},
   "source": [
    "MessagesState — это хранилище всех сообщений, включая запросы, ответы, вызовы инструментов и их результаты. Оно позволяет агенту помнить контекст и поддерживать связный диалог на всех этапах работы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed45a513-86f7-4f54-8655-59eb8cce10e2",
   "metadata": {},
   "source": [
    "В архитектуре ИИ-агента состояние (state) — это центральный элемент, который связывает все части системы между собой. Без него агент не может помнить, что уже было сделано, какие данные получены, какие вопросы заданы, и какие инструменты уже вызывались. В LangGraph и подобных системах часто используется структура под названием MessagesState — это специальный формат состояния, оптимизированный для диалогов с LLM.\n",
    "MessagesState содержит историю всех сообщений, переданных и полученных во время работы агента. Это включает:\n",
    "сообщения от пользователя (HumanMessage),\n",
    "системные инструкции (SystemMessage),\n",
    "ответы LLM (AIMessage),\n",
    "а также вызовы инструментов (tool_calls) и их ответы.\n",
    "Такая структура аналогична истории переписки в обычном мессенджере, но с тем отличием, что она используется как входной контекст для следующего шага LLM. То есть каждый раз, когда агент вызывает LLM для принятия решения, ему передаётся полный список предыдущих сообщений из MessagesState, чтобы модель могла учитывать весь предыдущий контекст.\n",
    "Это позволяет:\n",
    "задавать дополнительные вопросы без повторений,\n",
    "анализировать уже полученную информацию,\n",
    "выстраивать логическую цепочку действий,\n",
    "принимать решения с учётом всей истории диалога.\n",
    "Если бы у агента не было MessagesState, он начинал бы с \"нуля\" на каждом шаге, не помня, что уже обсуждалось. Это делало бы его поведение несогласованным и путаным. Поэтому MessagesState — это один из ключевых инструментов устойчивой работы ИИ-агента, особенно в задачах, где нужно вести сложный, пошаговый диалог и собирать информацию из разных источников.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72963570-c4ea-426d-a793-25acb3296f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd0f09d-9c80-4051-adc2-24b4a8724426",
   "metadata": {},
   "source": [
    "Почему ИИ-агенту важно иметь доступ ко всему состоянию (state) при каждом шаге?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267b05d-2735-429a-a0e8-c17016101ae1",
   "metadata": {},
   "source": [
    "Чтобы быстрее загружать инструменты\n",
    "Чтобы понимать, какие данные уже получены и не повторяться #\n",
    "Чтобы повторно запросить авторизацию\n",
    "Чтобы оптимизировать память компьютера\n",
    "Чтобы вывести состояние на экран"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a755e1-1d54-4f2b-8479-6fde6052d568",
   "metadata": {},
   "source": [
    "Агенту важно помнить, что уже обсуждалось и какие данные собраны, иначе он будет повторять одни и те же вопросы или делать ненужные вызовы инструментов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7922d3a1-81ea-4785-be2a-99b389ebdd31",
   "metadata": {},
   "source": [
    "Когда ИИ-агент выполняет сложную задачу — например, собирает информацию о клиенте и компании перед подачей жалобы — он действует в несколько шагов. На каждом этапе он может:\n",
    "задать пользователю вопрос,\n",
    "использовать инструмент для поиска,\n",
    "сделать вывод на основе полученной информации.\n",
    "Чтобы не \"сбиться\" с хода работы и не повторять действия, агенту нужен постоянный доступ к полному состоянию (state), особенно к истории всех сообщений (MessagesState). Это позволяет ему помнить:\n",
    "что уже получено от пользователя,\n",
    "какие параметры были найдены через поиск,\n",
    "какие tool_calls были уже выполнены,\n",
    "какие поля ещё остались незаполненными.\n",
    "Без этого память агента будет \"обнуляться\" на каждом шаге, и он может начать:\n",
    "снова спрашивать ФИО, которое уже есть,\n",
    "пытаться снова искать адрес, который уже найден,\n",
    "или, наоборот, преждевременно завершить работу, думая, что всё готово.\n",
    "Таким образом, сохранение и использование состояния — это способ сделать поведение агента логичным, устойчивым и ненавязчивым. Это особенно критично в бизнес-сценариях, где сбор данных требует точности и минимального раздражения пользователя.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a83538-6f1a-4887-b43f-94cf63213702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776618fa-c2b1-46b1-bd63-e98496fb274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что произойдёт, если не использовать состояние (state) в архитектуре ИИ-агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea6dcc-12f5-44cb-b35b-19b26e91b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Агент будет использовать устаревшие данные\n",
    "Агент не сможет выполнить tool_call\n",
    "Агент потеряет контекст и не сможет поддерживать связный диалог #\n",
    "Агент начнёт действовать как голосовой помощник\n",
    "Агент автоматически завершит работу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda0126-ef4d-431c-b630-9944f27b0d5d",
   "metadata": {},
   "source": [
    "Без состояния агент не запоминает, что уже получено. Он будет задавать повторяющиеся вопросы, дублировать шаги и нарушать логику последовательного диалога."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0f3a2-123f-4df5-872f-be8f0504a1b0",
   "metadata": {},
   "source": [
    "Состояние — это память агента. Если убрать state из архитектуры ИИ-агента, он перестаёт быть \"умным помощником\" и превращается в обычного \"забывчивого чат-бота\". Это означает, что на каждом новом шаге он не помнит:\n",
    "что вы уже обсуждали,\n",
    "какие данные были переданы пользователем,\n",
    "какие результаты уже получены от инструментов.\n",
    "В результате агент будет:\n",
    "задавать те же вопросы снова и снова,\n",
    "забывать, какие поля уже заполнены,\n",
    "не замечать противоречий или несостыковок в данных,\n",
    "терять общий смысл диалога и логическую структуру своей работы.\n",
    "Такой агент не способен справляться с многошаговыми задачами, а именно они и составляют суть применения агентных систем в реальной жизни: юридические кейсы, финансовые анкеты, техническая поддержка, автоматизация бизнес-процессов.\n",
    "Поэтому архитектура с сохранением состояния — это не просто улучшение, а необходимый элемент, чтобы ИИ-агент стал по-настоящему полезным инструментом. Без state невозможен ни осмысленный диалог, ни надёжный сбор данных, ни принятие решений на основе уже полученного контекста.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e3ad32-8d1c-44a4-b780-05cc90decc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82d88e-cc31-4431-b5f0-1eacfae53430",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что делает ToolNode в графе работы агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6cdc0-2c12-4345-82fb-8a59bf9909c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Запускает LLM повторно\n",
    "Выполняет вызовы инструментов, указанных в tool_calls #\n",
    "Переводит текст в другой язык\n",
    "Показывает пользователю результат\n",
    "Удаляет старые сообщения из памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a4354b-1cab-4748-81f4-70e2d526e8f7",
   "metadata": {},
   "source": [
    "ToolNode отвечает за выполнение инструментов, которые LLM запрашивает через tool_calls. Он исполняет действия, такие как поиск, взаимодействие с пользователем, API-вызовы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20977694-0161-41b3-8365-e1f6078a3a8e",
   "metadata": {},
   "source": [
    "ToolNode — это важный компонент архитектуры агента, построенного на LangGraph или других фреймворках с поддержкой инструментов. Он выполняет роль \"исполнителя\", приводящего в действие внешние функции, которые LLM не может выполнять напрямую.\n",
    "Когда LLM определяет, что ей не хватает данных или нужно действие во внешнем мире (например, поиск информации, запрос к пользователю, обращение к базе данных), она возвращает tool_call. Это инструкция: \"вызови вот этот инструмент с такими параметрами\".\n",
    "Однако сама модель не может запускать функции. Поэтому LangGraph передаёт управление в ToolNode — специальную ноду графа, которая:\n",
    "получает список tool_calls,\n",
    "находит соответствующие инструменты (по имени),\n",
    "вызывает их с нужными аргументами,\n",
    "сохраняет результат в state.\n",
    "Затем ToolNode возвращает выполнение обратно в следующую ноду (обычно gather_data_node), чтобы LLM могла обработать новый результат.\n",
    "Без ToolNode агент не сможет \"взаимодействовать\" с внешним миром — он будет просто разговаривать в вакууме. Поэтому ToolNode превращает текстовое мышление модели в реальные действия — делает ИИ агентом, а не просто чатом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23daea18-fc9d-4b04-bb8d-10d0db242588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e11aad-d0f7-45ce-9ab3-3d60b8afe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Почему ToolNode нельзя пропустить в графе, если агент работает с инструментами?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de3b8a-ef38-4ba8-81b5-436c9ab845f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Потому что он активирует GPT-4\n",
    "Без него система не будет использовать память\n",
    "Иначе tool_calls останутся без выполнения  #\n",
    "Он используется для подключения к интернету\n",
    "Иначе агент станет голосовым помощником"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e172bfe0-925c-470d-87a6-aafce612737c",
   "metadata": {},
   "source": [
    "Если ToolNode отсутствует, tool_calls останутся невыполненными, и агент не получит нужных данных. Это приведёт к сбоям в логике."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689abfc2-4424-4e12-b13f-a822a422e1ff",
   "metadata": {},
   "source": [
    "В архитектуре LangGraph вызов инструмента — это двухэтапный процесс:\n",
    "LLM предлагает, что нужно вызвать, возвращая tool_calls,\n",
    "Система действительно выполняет эти вызовы через ToolNode.\n",
    "Если в графе работы агента нет ноды ToolNode, то tool_calls, сгенерированные моделью, просто останутся в state и никак не будут исполнены. Это приведёт к сбою в логике работы: модель будет \"думать\", что инструмент уже сработал, хотя на самом деле никакое действие не произошло.\n",
    "Это всё равно что сказать \"позвони клиенту\", но не дать возможности сделать звонок. Агент останется в состоянии ожидания результата, которого никогда не будет. Или, хуже того, он решит, что всё готово, и завершит работу, не получив важную информацию.\n",
    "Поэтому ToolNode — обязательное звено в цепочке: LLM → tool_call → ToolNode → результат → LLM. Он превращает намерение в действие.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e4f3b-c405-4e4a-969b-ac4f69c791ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbea8ef-3fba-44f5-8a7b-41c9307752ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Когда ToolNode возвращает управление обратно LLM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32a189-2e76-4cb5-80f9-040adc48912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Сразу после старта\n",
    "Только если возникает ошибка\n",
    "После выполнения всех инструментов, указанных в tool_calls #\n",
    "Только при переходе к новой задаче\n",
    "После подтверждения от пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaa399e-d595-49e1-88bd-80c5f6f9edbc",
   "metadata": {},
   "source": [
    "ToolNode возвращает управление обратно LLM, когда завершает все действия, указанные в tool_calls. Только после этого модель продолжает работу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fdb4b5-4ffd-4c0d-a380-3fa8d2691edd",
   "metadata": {},
   "source": [
    "Когда агент доходит до ToolNode, он передаёт туда все tool_calls, сформированные моделью. Это могут быть запросы к поисковику, вопросы к пользователю, обращения к базам данных и т.п. ToolNode выполняет все эти действия последовательно или параллельно, в зависимости от настроек, и сохраняет результаты в state.\n",
    "Только когда все вызовы завершены, ToolNode передаёт управление обратно в граф — обычно в ту же gather_data_node, где снова запускается LLM. Теперь модель \"видит\" результат работы инструментов и может:\n",
    "продолжить диалог,\n",
    "уточнить недостающие данные,\n",
    "завершить работу, если всё собрано.\n",
    "Таким образом, ToolNode работает как промежуточный \"исполнительный слой\", а LLM — как \"мозг\", который принимает решения до и после действий. Такой цикл — основа агентной архитектуры.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c07ce-e1ba-43df-ba6c-031c4fc6005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ec3232-b352-4c44-9835-b688831f70e0",
   "metadata": {},
   "outputs": [],
   "source": [
    " Зачем нужен системный промпт (SystemMessage) в работе агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4bd6d7-9383-43f3-93a1-af7c1512a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Чтобы уменьшить количество токенов\n",
    "Чтобы сгенерировать случайный ответ\n",
    "Чтобы объяснить агенту его роль и правила поведения  #\n",
    "Чтобы перезагрузить граф\n",
    "Чтобы заменить API-ключ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b96d4-f31f-461b-9b55-f7071a7d9d5e",
   "metadata": {},
   "source": [
    "Системный промпт задаёт поведение агента: кто он, какую задачу решает, какие данные собирает и какие инструменты доступны. Это \"инструкция\", которой он следует на каждом шаге."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014caf5-0e15-4908-a4e5-28f040edb2b1",
   "metadata": {},
   "source": [
    "Системный промпт — это одно из ключевых звеньев в управлении поведением ИИ-агента. Он работает как инструктаж перед началом задачи, в котором LLM объясняется:\n",
    "кто она сейчас (например, \"Ты — помощник юриста\"),\n",
    "какую цель ты должна достичь (например, \"Собери все данные о клиенте и компании\"),\n",
    "какие правила важны (например, \"Не завершай работу, пока не соберёшь всё\"),\n",
    "какие инструменты доступны (например, \"Для поиска используй Tavily, для вопросов — HumanInput\").\n",
    "Эта инструкция передаётся в виде специального сообщения — SystemMessage, и сохраняется в MessagesState. Она не видна пользователю, но LLM использует её как руководство к действию при каждом запуске.\n",
    "Без системного промпта поведение агента становится неопределённым: он может начать просить все данные сразу, не использовать инструменты, завершать работу преждевременно, или выдавать текст в свободной форме. С правильно составленным промптом поведение становится структурированным, предсказуемым и управляемым, а агент выполняет свою задачу по шагам — как обученный сотрудник."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60848ae6-8674-42a0-bf9d-c4336d014041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f016924-9069-4ea3-95aa-d2fba183e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что произойдёт, если в промпте не объяснить, как использовать инструменты?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56978cb-2292-48c2-b82a-8f4e7e28435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Агент начнёт автоматически использовать все инструменты\n",
    "Агент отключится от модели\n",
    "Агент будет просить у пользователя все данные вручную  #\n",
    "Агент перейдёт в режим обучения\n",
    "Агент начнёт задавать случайные вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab92822-cab8-4294-ba9f-c7b011e9a8ec",
   "metadata": {},
   "source": [
    "Без инструкции об инструментах агент не понимает, что ему доступны внешние действия. В результате он \"ленится\" и просит у пользователя всё сразу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e663701-bca6-455b-8ac9-62618bbcd523",
   "metadata": {},
   "source": [
    "LLM — это обученная языковая модель, а не магический интеллект. Она не \"знает\", что ей доступны инструменты, пока ей об этом не скажут. Если в SystemMessage не указано, что можно использовать search, human или другие tools, модель просто будет действовать, как в обычной переписке.\n",
    "На практике это означает: вместо того чтобы делать отдельные поиски или задавать точечные вопросы, агент сгенерирует длинный список того, что нужно получить, и передаст всё пользователю. Например, он может сказать: \"Пожалуйста, напишите полностью ФИО, паспортные данные, ИНН компании, адрес, дату и номер покупки и т.д.\" — одним списком.\n",
    "Это не только неудобно, но и снижает надёжность: если пользователь пропустит часть, агент может не понять, что нужно задать уточняющий вопрос. Чтобы избежать этого, важно в промпте чётко объяснить:\n",
    "какие инструменты доступны,\n",
    "что и когда нужно использовать,\n",
    "и как агент должен себя вести."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde01c92-1461-4837-b3cd-43442f7ccc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea52c2f-c17b-4382-92c2-a52e5b048457",
   "metadata": {},
   "outputs": [],
   "source": [
    "Как в промпте задать агенту \"роль\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb107555-3284-46f5-ba69-454cb7051388",
   "metadata": {},
   "outputs": [],
   "source": [
    "Использовать JSON-схему\n",
    "Указать это в поле API-ключа\n",
    "Сказать в SystemMessage, кем является агент и какая его задача #\n",
    "Настроить цвет интерфейса\n",
    "Выбрать модель GPT-3 вместо GPT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8acf68-9e44-4f13-bb51-d26bdb16d516",
   "metadata": {},
   "source": [
    "Чтобы задать агенту \"роль\", нужно в системном промпте прямо написать, кто он и что должен делать. Это влияет на его стиль общения, поведение и цель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba9fae4-c4f5-40f3-a68e-5a9080bc39af",
   "metadata": {},
   "source": [
    "В языковых моделях роль задаётся через промпт — в частности, через SystemMessage. Это сообщение вводится в самом начале диалога и говорит LLM, в каком \"образе\" она должна действовать. Например:\n",
    "\"Ты — помощник юриста, который собирает данные у клиента\"\n",
    "\"Ты — вежливый консультант интернет-магазина\"\n",
    "\"Ты — технический саппорт, который помогает настроить программу\"\n",
    "Это формирует не только стиль общения (деловой, нейтральный, дружелюбный), но и фокус мышления модели: какие данные собирать, что считать завершением работы, нужно ли уточнять, как действовать при неполной информации.\n",
    "Такой подход делает поведение агента стабильным, воспроизводимым и удобным для пользователя. Он знает, с кем имеет дело, а модель знает, что от неё ожидают.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378ddacf-68d8-4290-bea4-198c08c37007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da820d-9d62-473d-b214-7ac155fbeccc",
   "metadata": {},
   "source": [
    "Что означает понятие \"Graph\" (граф) в архитектуре ИИ-агента, например, на платформе LangGraph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f6cb8-f531-4bac-931e-aecc76c00eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Список всех запросов пользователя\n",
    "Набор диаграмм и визуализаций\n",
    "Структура из связанных между собой шагов, определяющих поведение агента  #\n",
    "Таблица с логами вызовов инструментов\n",
    "Список токенов, использованных моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fabc18c-663f-4d8b-b272-26797c52b15b",
   "metadata": {},
   "source": [
    "Graph — это схема, по которой агент выполняет свою задачу: шаг за шагом. Каждый узел (нода) — это действие (например, запуск LLM), а стрелки между ними задают логику переходов (например, продолжить, завершить, вызвать инструмент)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73c567-117d-4d7b-bdc7-80554304bbaf",
   "metadata": {},
   "source": [
    "В контексте ИИ-агентов Graph (граф) — это не график или визуализация, а структура, описывающая поведение агента как последовательность логически связанных шагов.\n",
    "Представь, что агент должен собрать информацию у пользователя, найти дополнительные данные в интернете, проверить, всё ли готово, и затем выдать результат. Это не линейный процесс, а условный маршрут:\n",
    "иногда нужно повторить вопрос,\n",
    "иногда — вызвать поиск,\n",
    "иногда — просто завершить.\n",
    "Всё это можно выразить в виде графа:\n",
    "ноды (узлы) — это действия (например, запуск модели, вызов инструмента),\n",
    "рёбра (переходы) — это условия, по которым агент переходит от одного действия к другому.\n",
    "Граф определяет:\n",
    "где начинается работа агента (например, gather_data_node),\n",
    "куда он пойдёт, если нужно вызвать инструмент (ToolNode),\n",
    "что произойдёт, если всё собрано (END),\n",
    "как обрабатываются повторные шаги.\n",
    "Таким образом, граф — это как сценарий поведения ИИ-агента, только не в виде кода, а в виде структуры, по которой он двигается в зависимости от условий.\n",
    "LangGraph и другие системы позволяют явно строить такие графы, используя функции вроде add_node, add_edge, add_conditional_edges, и это делает агента гибким и управляемым. Не просто болтающим ботом, а системой, которая может принимать решения, повторять действия, собирать данные пошагово и завершать работу тогда, когда нужно.\n",
    "Именно граф превращает цепочку запросов и ответов в агента с разумной стратегией поведения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0823dea-024d-4060-b5fe-357b7254d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f4a95-ed89-4c57-a8ae-4f20c5eb9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что делает функция add_conditional_edges в LangGraph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59adccea-cd14-474c-9ca4-e5e926d6f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "Оптимизирует токены в промпте\n",
    "Добавляет инструменты в список\n",
    "Создаёт переходы между нодами на основе условий #\n",
    "Сохраняет JSON в state\n",
    "Перезапускает цикл агента"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7b33ff-ed98-4817-b6c4-6f801115c84c",
   "metadata": {},
   "source": [
    "add_conditional_edges позволяет задать: куда агент пойдёт дальше после выполнения текущей ноды — в зависимости от условий (например, есть ли tool_call или задача завершена)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e6463-9ac9-4a87-b16f-238adbc369f6",
   "metadata": {},
   "source": [
    "LangGraph строит поведение агента как граф — систему связанных нод (узлов), где каждая нода выполняет одну задачу: например, вызвать LLM, выполнить инструмент, обработать результат. Чтобы граф не был просто линейной цепочкой, используются условные переходы. Они позволяют агенту выбирать путь: продолжить, повторить, завершить или использовать инструмент.\n",
    "Функция add_conditional_edges — это способ задать условия переходов. Например:\n",
    "если LLM сгенерировал tool_calls → перейти в ToolNode\n",
    "если задача завершена → перейти в END\n",
    "если данных недостаточно → вернуться в gather_data_node\n",
    "Без этой функции граф был бы статичен: после каждой ноды выполнялась бы одна и та же следующая. Но реальный агент должен принимать решения на каждом шаге, и именно условные переходы делают его поведение гибким.\n",
    "Эта логика похожа на if/else в программировании, только применяется на уровне структуры поведения агента. В результате граф превращается в \"мозг\", определяющий стратегию действий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9ba96-890b-498a-b8c7-ceda98ff81c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfbf3af-c719-4f77-a702-634d08d2799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что происходит в ноде gather_data_node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1d1d8-12a4-4c6d-9d37-f293547be1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    " Агент показывает результат пользователю\n",
    "B. Агент запускает голосовой ввод\n",
    "C. LLM анализирует контекст и решает, какие действия нужны дальше  #\n",
    "D. Агент выполняет инструмент напрямую\n",
    "E. Агент очищает память"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b81c50-4a28-44c6-9014-d063644b1409",
   "metadata": {},
   "source": [
    "В gather_data_node LLM просматривает весь контекст и решает: нужно ли использовать инструмент, задать вопрос, завершить или продолжить."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460190a7-5cd2-4681-a4ed-af42b0bf789d",
   "metadata": {},
   "source": [
    "gather_data_node — это ключевая точка в цикле агента. Именно здесь запускается языковая модель (LLM), которая:\n",
    "получает всё текущее состояние (MessagesState),\n",
    "анализирует, какие данные уже есть,\n",
    "сравнивает с задачей из промпта,\n",
    "и возвращает либо финальный результат, либо tool_call для следующего шага.\n",
    "Это — момент принятия решений. Если агент уже собрал всё нужное — он возвращает итоговый JSON. Если не хватает информации — он может либо задать уточняющий вопрос (через human), либо сформировать запрос в поиск (через search). А если вообще ничего не понял — может вернуться к началу.\n",
    "Таким образом, gather_data_node — это \"мозг\" агента, который на каждом шаге оценивает ситуацию и выбирает, что делать дальше. Именно здесь промпт-инжиниринг особенно важен: то, как ты обучишь модель в SystemMessage, напрямую влияет на поведение в этой ноде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a197f59-b255-4060-8c7e-bdb7ca5a19ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff46fd7-c15e-45e2-ba90-c31db912ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что происходит после выполнения инструментов в ноде tools?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e6106-e7ea-4ad0-9b2f-a0c3d7cc6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "Агент завершает работу\n",
    "Агент сбрасывает все данные\n",
    "Агент возвращается в gather_data_node, чтобы проанализировать результат  #\n",
    "Агент перезапускает весь граф\n",
    "Агент отправляет результат в email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c46fa-0749-441a-be23-942f75b22c30",
   "metadata": {},
   "source": [
    "После tools агент возвращается к gather_data_node, чтобы LLM получила результат работы инструментов и решила, что делать дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621eb297-ff78-4322-a92d-8b4ed4fe3eb8",
   "metadata": {},
   "source": [
    "После того как LLM сгенерировала tool_call, LangGraph переходит в ноду tools, где выполняется вызов нужного инструмента: например, поиск или вопрос пользователю. Но инструмент сам не принимает решений. Он просто возвращает результат — текст, число, список, и т.д.\n",
    "Этот результат нужно передать обратно LLM, чтобы она:\n",
    "поняла, какие данные пришли,\n",
    "оценила, закрыли ли они задачу,\n",
    "и либо продолжила, либо завершила работу.\n",
    "Именно для этого после tools всегда идёт возврат в gather_data_node. Это создаёт циклический маршрут:\n",
    "LLM → инструмент → результат → снова LLM.\n",
    "Без этого цикла агент не сможет пошагово собирать информацию и действовать по ситуации. Он станет \"одноразовым\". А с этим циклом он работает, пока задача не будет решена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0010b-51f0-4708-ba00-81f53a2bd3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ac5a8-38ed-4c59-bac3-07d35d722385",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что такое HumanInputTool в архитектуре ИИ-агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97104f4-2d70-420e-b441-6a43978322d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Интерфейс для настройки голосового ввода\n",
    "Инструмент для генерации случайных вопросов\n",
    "Средство, с помощью которого агент задаёт вопрос человеку и ждёт ответа #\n",
    "Блок хранения паспортных данных\n",
    "Система, позволяющая агенту редактировать промпт на лету"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009413ca-2814-4872-9d98-1f1ebd2fc23e",
   "metadata": {},
   "source": [
    "HumanInputTool — это инструмент, который агент использует, чтобы напрямую задать вопрос пользователю. Агент формулирует tool_call, а затем система выводит вопрос человеку и ждёт ввода ответа перед продолжением работы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b60fc2-50a7-430e-aff7-9757129aef4c",
   "metadata": {},
   "source": [
    "В архитектуре ИИ-агента есть два основных источника данных:\n",
    "Информация, которую можно найти автоматически (например, через поиск).\n",
    "Информация, которую может сообщить только пользователь.\n",
    "Именно для второго случая используется HumanInputTool. Это инструмент, позволяющий агенту задать пользователю конкретный вопрос и приостановить выполнение до тех пор, пока не будет получен ответ.\n",
    "Когда LLM анализирует задачу и понимает, что ей не хватает, скажем, паспортных данных, она не просто пишет текстом: \"пожалуйста, укажите паспорт\", а формирует специальный tool_call — вызов инструмента human, с текстом вопроса. После этого управление передаётся в ToolNode, и система:\n",
    "выводит вопрос пользователю,\n",
    "ожидает текстовый ответ (например, \"Иванов Иван Иванович, 4444 444444\"),\n",
    "возвращает этот ответ обратно в state как часть диалога.\n",
    "Далее агент продолжает работу, уже имея эти данные.\n",
    "HumanInputTool особенно важен в задачах, где автоматизация ограничена: личные данные, пояснения, числа, даты, мнения — всё, что нельзя заранее предсказать или найти в интернете. Агенту нужен канал общения с человеком, и именно этот инструмент его реализует.\n",
    "Важно, что HumanInputTool делает поведение агента гибким и интерактивным: он не просто действует по шаблону, а может уточнять, дорабатывать и собирать информацию постепенно. Это превращает агента в \"живого помощника\", а не в опросник с кнопками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e537b2-eb65-4a3d-a642-6a6e5be17eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f2b84-5751-4c4d-9dab-3797c95a13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Когда ИИ-агенту стоит использовать HumanInputTool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c478e-d29d-48d0-af03-9b67a1d117d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Когда нужно выполнить математический расчёт\n",
    "Когда нужна личная информация, которую нельзя найти в интернете  #\n",
    "Когда нужно завершить работу графа\n",
    "Когда агент пишет итоговое письмо\n",
    "Когда нужно изменить код Python-функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc990b6b-6153-42a5-88db-dc5452430a00",
   "metadata": {},
   "source": [
    "HumanInputTool используется, если агенту нужна информация, которую невозможно найти автоматически — например, ФИО клиента или сумма покупки. Это позволяет агенту задать человеку вопрос и продолжить работу после получения ответа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec38104-a60c-4740-a433-05ed0724ad58",
   "metadata": {},
   "source": [
    "ИИ-агенты могут использовать разные инструменты для получения информации: поисковые API, базы данных, внутреннюю память. Но в некоторых случаях только человек может предоставить нужные данные — например:\n",
    "ФИО, паспортные данные, дата рождения\n",
    "Номер договора, высланный на бумаге\n",
    "Причина возврата товара, изложенная в свободной форме\n",
    "Для таких случаев и существует HumanInputTool. Агенту достаточно понять, что нужной информации нет в контексте или в открытом доступе, и он формирует tool_call с вопросом. После этого:\n",
    "Система выводит вопрос человеку.\n",
    "Получает текстовый ответ.\n",
    "Ответ добавляется в state, и агент продолжает рассуждение.\n",
    "Пример:\n",
    "Агент: Пожалуйста, укажите дату покупки.\n",
    "Пользователь: 01.10.2024\n",
    "Агент: Отлично. Теперь укажите сумму и номер.\n",
    "Этот процесс делает взаимодействие более похожим на диалог, чем на обычную форму.\n",
    "Использовать human надо, когда:\n",
    "нет другой опоры (поиск не поможет),\n",
    "требуется подтверждение от пользователя,\n",
    "агенту нужна точность или контекст.\n",
    "Это делает работу агента гибкой и приближает к реальному консультанту.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f174fd-af4f-4831-b0c7-7647c764f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e4c13c-9cc5-4613-97d7-661cb9a63ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Как агент обрабатывает ответ пользователя, полученный через HumanInputTool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84635d5-e1e2-4379-a0d3-ac47cef338ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Сохраняет ответ как переменную, но не использует\n",
    "Удаляет старые сообщения и заменяет на новые\n",
    "Добавляет ответ в историю сообщений (state[\"messages\"])  #\n",
    "Преобразует ответ в код Python\n",
    "Передаёт его напрямую в систему Tavily\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e93df5-1fb4-4c80-b3c4-795033a12309",
   "metadata": {},
   "source": [
    "После получения ответа через HumanInputTool агент добавляет его в историю сообщений (messages). Таким образом, LLM воспринимает ответ как обычное сообщение от пользователя и может использовать его в следующем шаге рассуждения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680358a7-1342-4d4c-aede-2df5bc6c28d3",
   "metadata": {},
   "source": [
    "Когда агент задаёт вопрос через инструмент human, система приостанавливает выполнение и ждёт текстовый ответ от пользователя. После того как ответ получен, он не просто \"где-то сохраняется\", а добавляется в историю сообщений, в объект state[\"messages\"].\n",
    "Это делается намеренно, чтобы LLM видела весь контекст общения. LLM не понимает переменных и состояний в классическом смысле программирования — она опирается на последовательность сообщений. Поэтому:\n",
    "агент видит вопрос, который он сам задал (в виде AssistantMessage с tool_call),\n",
    "и ответ пользователя (в виде HumanMessage).\n",
    "На следующем шаге LLM уже имеет доступ ко всем сообщениям, включая только что полученные. Она может интерпретировать их, задавать уточняющие вопросы, делать выводы.\n",
    "Например:\n",
    "Вопрос: Укажите сумму покупки.\n",
    "Ответ: 100 000 руб.\n",
    "LLM: Отлично, теперь осталось уточнить дату покупки.\n",
    "Без добавления в messages этот ответ оказался бы \"невидим\" для модели. Поэтому ToolNode, получив ответ, всегда оформляет его как новое сообщение в истории, чтобы диалог был полным и понятным для LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28196f38-8c42-4ba2-a8ec-7e0ebe43e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e075304d-6f5f-4047-bff4-25092eb425c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "В каком случае использование HumanInputTool приведёт к ошибке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca5c06-5998-4ef0-834b-a9b95e819d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Когда агенту нужно уточнить имя пользователя\n",
    "Когда пользователь не отвечает на запрос  #\n",
    "Когда заданный вопрос слишком длинный\n",
    "Когда вопрос содержит эмодзи\n",
    "Когда одновременно вызываются несколько human-инструментов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b8faa-21e4-425a-be32-39120b13073c",
   "metadata": {},
   "source": [
    "HumanInputTool требует реального ответа от пользователя. Если пользователь не отвечает или ответ пустой, агент «зависает» в ожидании. Это не техническая ошибка, но сценарий «зависания» нужно обрабатывать отдельно.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c68501-e828-466a-9bb6-8310cf9a0ac5",
   "metadata": {},
   "source": [
    "HumanInputTool — это интерфейс для запроса информации у пользователя. В отличие от API-инструментов вроде Tavily, он требует вовлечённости человека. После генерации tool_call типа human, агент приостанавливает выполнение до получения ответа. В этом и состоит основная уязвимость:\n",
    "Если пользователь не отвечает, агент остаётся в подвешенном состоянии:\n",
    "LangGraph продолжает «ждать» ответа,\n",
    "цикл не завершается,\n",
    "другие действия не выполняются.\n",
    "На практике это выглядит как зависание или тайм-аут, особенно в автоматических пайплайнах. Поэтому при использовании HumanInputTool важно:\n",
    "показывать пользователю внятный запрос,\n",
    "устанавливать дедлайны или механизмы напоминаний,\n",
    "предусматривать стратегию выхода (например, отправить уведомление или завершить с сообщением об ошибке).\n",
    "Никаких технических ограничений на длину вопроса, наличие эмодзи или даже множественные tool_call в структуре LangGraph нет, но сам ToolNode может исполнять только один tool_call за раз. Поэтому вариант E некорректен: LangGraph просто выберет первый human-вызов и проигнорирует остальные до следующего цикла.\n",
    "Таким образом, ключевая проблема HumanInputTool — это зависимость от внешнего ответа, который может не поступить. Это требует дополнительной логики для устойчивости агента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfb6e6-456f-4d4a-817c-e302ac82da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef14b0-bd8d-4b6a-8b92-0be6d2f2768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Зачем агенту нужна проверка полноты данных (is_complete)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac4eef6-3794-443a-b59b-8b312d72f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Чтобы проверить орфографию текста\n",
    "Чтобы завершить работу, когда собраны все нужные данные  #\n",
    "Чтобы сохранить сообщения в файл\n",
    "Чтобы отправить данные пользователю\n",
    "Чтобы уменьшить токены в сообщениях"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427e30e2-41ff-4d02-b1bf-20dbf8a67934",
   "metadata": {},
   "source": [
    "Проверка полноты (is_complete) нужна, чтобы понять, завершил ли агент сбор всех необходимых данных. Если всё собрано — граф завершает работу. Если нет — продолжается цикл уточнений и вызовов инструментов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651d5c0f-983b-480e-aa8e-cf7f93576737",
   "metadata": {},
   "source": [
    "В агентных системах, особенно построенных на LangGraph, важна контрольная точка, где агент решает: «Я всё сделал» или «Нужно ещё поискать / уточнить». Именно для этого вводится функция проверки полноты данных — чаще всего она называется is_complete() или реализуется как часть логики should_continue.\n",
    "Эта проверка может работать на основе:\n",
    "наличия всех нужных полей (например, все ключи в case_data присутствуют),\n",
    "специфических условий (например, если в тексте упоминается \"не найдено\", значит — не всё готово),\n",
    "шаблонов, регулярных выражений и т. п.\n",
    "Без is_complete агент может:\n",
    "завершить работу слишком рано, не собрав важные данные (как в ранней версии примера с World Class),\n",
    "зациклиться, продолжая спрашивать одно и то же,\n",
    "не отдать результат в нужном формате. Проверка полноты — это механизм контроля качества и завершения, своего рода валидатор, который работает по следующему принципу:\n",
    "Смотрим на собранные данные в state.\n",
    "Проверяем, все ли поля заполнены.\n",
    "Возвращаем флаг True — если да, или False — если нет.\n",
    "При True граф завершает выполнение через END. При False — возвращается к LLM или инструментам.\n",
    "Таким образом, без is_complete невозможно сделать надёжного агента. Это обязательная часть любого продвинутого workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c70d36-3f84-4572-907f-29b552b83f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c49e5-b865-4491-9ef1-8171fde97fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Когда агент может ошибиться при проверке полноты данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725babeb-d245-4776-b9eb-164fd3fc0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Если все поля заполнены, но данные некорректны  #\n",
    "Если пользователь вводит данные слишком быстро\n",
    "Если модель слишком большая\n",
    "Когда используется human tool\n",
    "Если не хватает памяти в стейте"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a151529-ec8c-45cc-af95-d949ceb126d7",
   "metadata": {},
   "source": [
    "Агент может завершить работу, если формально все поля заполнены, даже если данные в них ошибочны или фиктивны. Проверка полноты не гарантирует достоверность, только наличие информации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df51d815-8d68-42c1-a64c-de4d43f174cb",
   "metadata": {},
   "source": [
    "Функция is_complete() в агентной системе отвечает лишь за формальную полноту данных, то есть, были ли все необходимые поля получены. Однако здесь кроется один из важных подводных камней: агент может завершить свою работу, даже если собранные данные — некорректны, неполные или вымышленные.\n",
    "Пример:\n",
    "Пользователь на вопрос об ИНН вводит: 1234567890 (вымышленный номер).\n",
    "Агент видит, что поле ИНН заполнено.\n",
    "is_complete() возвращает True, потому что все ключи присутствуют.\n",
    "Агент завершает работу, не проверяя, что ИНН фейковый.\n",
    "Это типичный случай логической ошибки, когда система полагается на наличие данных, а не на их достоверность.\n",
    "Также возможны и другие ситуации:\n",
    "Агент получает текст \"Не знаю\" или \"не помню\", но засчитывает это как ответ.\n",
    "Ответ включает все поля, но в неверном формате (например, дата в виде 32.15.24).\n",
    "Пользователь отвечает бессмысленным текстом, который не был проверен.\n",
    "Такие ошибки особенно часты в системах, где агент собирает информацию у человека (human tool) и не валидирует ответ. Чтобы избежать этого:\n",
    "внедряют дополнительные проверки формата (например, regex),\n",
    "запускают валидаторы на ключевые поля,\n",
    "просят LLM дополнительно проанализировать, являются ли данные правдоподобными.\n",
    "Вывод: проверка полноты ≠ проверка корректности. Это важно учитывать при проектировании систем, особенно в юридических, медицинских и финансовых задачах, где ошибка может дорого стоить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150e328-9d23-48ec-bdc4-37cda4dfb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#44"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce354c-ac38-46e3-9b43-1d47da649cf3",
   "metadata": {},
   "source": [
    "Что должно произойти, чтобы агент завершил свою работу и не запрашивал больше данных?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7bc907-f219-40c4-ae09-8c9c4614bf58",
   "metadata": {},
   "source": [
    "Агент получил сообщение от пользователя с текстом \"Хватит\"\n",
    "Все необходимые поля заполнены, и функция проверки возвращает True  #\n",
    "LLM решил, что уже достаточно информации\n",
    "Сработал инструмент поиска Tavily\n",
    "Human tool завершил ввод текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83f92a-2d49-4228-a9f7-1d94c5c365f6",
   "metadata": {},
   "source": [
    "Агент завершает работу, когда все требуемые данные собраны, и функция проверки (например, is_complete) возвращает True. Это означает, что информация по всем полям присутствует, и больше действий не требуется."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00f9d4d-ab9e-428d-9c2e-7fe01440ed17",
   "metadata": {},
   "source": [
    "Процесс завершения работы агента зависит от заранее заданной логики в графе. В системах, построенных с помощью LangGraph или других агентных фреймворков, чаще всего используется функция проверки, определяющая, достаточно ли данных для финального ответа. Эта функция может называться, например, is_complete() и быть привязана к узлу с условным переходом (add_conditional_edges).\n",
    "Чтобы агент завершил свою работу, должны быть выполнены следующие условия:\n",
    "Собраны все ключевые поля, определённые в задаче.\n",
    "Пример:\n",
    "Указано юридическое название компании\n",
    "Присутствует ИНН\n",
    "Получены паспортные данные клиента\n",
    "Есть информация о покупке\n",
    "Функция проверки возвращает True.\n",
    "Агент вызывает эту функцию после очередного шага (например, после сбора данных от human tool или выполнения tool_call). Если результат положительный — переход идёт к END, иначе — к следующему шагу (например, вызову инструмента или дополнительному вопросу).\n",
    "Никакие внешние события (например, текст “Хватит”) сами по себе не останавливают граф, если не запрограммированы. LLM не принимает решения самостоятельно — она генерирует сообщения, а логика управления — на стороне графа.\n",
    "tool_calls и human tool — лишь части механизма сбора данных. Они не определяют, когда задача завершена. Это делает только логика графа.\n",
    "Таким образом, завершение — это результат логической проверки того, что всё собрано, и в контексте работы агента больше нет необходимости. Без такой проверки агент может “петлять” в бесконечном цикле вопросов или, наоборот, завершиться преждевременно.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56145fab-78d5-4b81-9701-1189e311b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d2610-ed96-4e93-ad54-3af0eb8ad02d",
   "metadata": {},
   "source": [
    "📚 Что нужно добавить для полной картины (базовый уровень)\n",
    "1. Обработка ошибок и исключений\n",
    "Что делать, если tool_call не сработал?\n",
    "\n",
    "Как агент может «переспросить» или изменить запрос?\n",
    "\n",
    "Механизм повторного запроса (retry) или fallback.\n",
    "\n",
    "2. Долгосрочная память и контекст\n",
    "Чем отличается история сообщений от памяти?\n",
    "\n",
    "Примеры использования памяти (например, клиентские профили).\n",
    "\n",
    "Подключение внешней памяти (векторное хранилище, Redis и др.)\n",
    "\n",
    "3. RAG (Retrieval-Augmented Generation)\n",
    "Что это и зачем нужно?\n",
    "\n",
    "Как подключается к агенту.\n",
    "\n",
    "Как работает связка: запрос → поиск → ответ на основе найденного.\n",
    "\n",
    "4. Мультиагентные системы\n",
    "Как один агент может делегировать задачу другому.\n",
    "\n",
    "Примеры ролей: сборщик данных, юрист, аналитик.\n",
    "\n",
    "Как координировать агентов.\n",
    "\n",
    "5. Интеграция с внешними системами\n",
    "Примеры API-интеграций: CRM, базы данных, документы.\n",
    "\n",
    "Как агент может инициировать транзакции или действия вне своей среды.\n",
    "\n",
    "6. Оценка качества работы агента\n",
    "Метрики: полнота, точность, количество шагов, успешность.\n",
    "\n",
    "Как тестировать агента.\n",
    "\n",
    "Примеры ошибок и как их отслеживать.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46f04cc-e662-4398-8993-2fed96a6b275",
   "metadata": {},
   "source": [
    "На каких языках программирования пишут ИИ-агентов\n",
    "ИИ-агенты — это концепция, а не язык. Однако на практике чаще всего используются:\n",
    "\n",
    "✅ Python (основной язык):\n",
    "Практически все фреймворки: LangChain, LangGraph, LlamaIndex, CrewAI и т.д.\n",
    "\n",
    "Простота интеграции с OpenAI API, Hugging Face, поисковыми системами, базами данных.\n",
    "\n",
    "Огромная поддержка ML/AI библиотек.\n",
    "\n",
    "✅ JavaScript / TypeScript\n",
    "Особенно для веб-интеграций (например, через LangChain.js).\n",
    "\n",
    "Для интерфейсов, чат-ботов и приложений на React.\n",
    "\n",
    "Можно строить веб-агентов или фронтенды для агентов.\n",
    "\n",
    "☑️ Go / Rust\n",
    "Подходит для высокопроизводительных агентов, но меньше библиотек для LLM.\n",
    "\n",
    "Используется в распределённых системах или низкоуровневой логике.\n",
    "\n",
    "☑️ Java / C#\n",
    "В корпорациях с устоявшейся экосистемой.\n",
    "\n",
    "Часто интеграции делаются через REST API к Python-модулю агента.\n",
    "\n",
    "Если ты планируешь развивать учебник дальше, вот что можно включить:\n",
    "\n",
    "📖 Глоссарий (tool_call, state, memory, prompt, tool_node и т.п.)\n",
    "\n",
    "📂 Структура реального проекта агента (файлы, зависимости, пример API)\n",
    "\n",
    "🔁 Раздел «часто встречающиеся ошибки»\n",
    "\n",
    "🧩 Блок «как придумать нового агента под бизнес-задачу»\n",
    "\n",
    "✍️ Мини-практикум: «Сделай своего агента шаг за шагом»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c7d7b-aefa-4eb9-bd3a-89fac27f2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "......................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51358d03-ba73-4f53-b3ce-76e53ef8ca42",
   "metadata": {},
   "source": [
    "🧠 Глоссарий по ИИ-агентам\n",
    "1. tool_call\n",
    "Что это:\n",
    "Запрос от языковой модели (LLM) на вызов одного из инструментов, доступных агенту.\n",
    "\n",
    "Пример:\n",
    "LLM просит: «Сделай поиск в интернете по запросу “ИНН компании Wordclass”» — это и есть tool_call.\n",
    "\n",
    "Содержит:\n",
    "\n",
    "name: название инструмента\n",
    "\n",
    "args: аргументы (например, поисковый запрос)\n",
    "\n",
    "id: уникальный идентификатор вызова\n",
    "\n",
    "type: всегда tool_call\n",
    "\n",
    "2. tool_node\n",
    "Что это:\n",
    "Нода (узел) в графе, которая исполняет tool_call. Она получает инструкцию от LLM и вызывает соответствующий инструмент.\n",
    "\n",
    "Пример:\n",
    "LLM запрашивает поиск — tool_node выполняет TavilySearch и возвращает результат обратно в LLM.\n",
    "\n",
    "3. state / MessagesState\n",
    "Что это:\n",
    "Общее \"состояние\" агента — память, которую он использует во время работы.\n",
    "MessagesState — частный случай, где хранятся сообщения от пользователя, LLM, и инструментов.\n",
    "\n",
    "Зачем нужно:\n",
    "Чтобы LLM имел доступ ко всей истории общения и мог строить логичное поведение.\n",
    "\n",
    "4. prompt / system prompt\n",
    "Что это:\n",
    "Инструкция для LLM, задающая поведение агента.\n",
    "Системный промпт — это \"роли\" и правила работы агента.\n",
    "\n",
    "Пример:\n",
    "«Ты — ассистент юриста. Сначала собери все данные, используй инструменты...» — это системный промпт.\n",
    "\n",
    "5. graph / StateGraph\n",
    "Что это:\n",
    "Структура, описывающая путь, по которому агент выполняет задачи. Включает ноды и переходы между ними.\n",
    "\n",
    "Пример:\n",
    "Нода gather_data_node → проверка should_continue → либо tool_node, либо END.\n",
    "\n",
    "6. node / gather_data_node\n",
    "Что это:\n",
    "Конкретный шаг в графе. Ноды — это функции, которые что-то делают: вызывают LLM, инструменты и т.д.\n",
    "\n",
    "Пример:\n",
    "gather_data_node вызывает LLM и добавляет системный промпт. Это центральная нода.\n",
    "\n",
    "7. human tool / HumanInputTool\n",
    "Что это:\n",
    "Инструмент, позволяющий LLM обратиться к пользователю с вопросом.\n",
    "Когда данных не хватает — агент может задать уточняющий вопрос.\n",
    "\n",
    "Пример:\n",
    "«Пожалуйста, уточните, когда и за сколько вы купили абонемент.»\n",
    "\n",
    "8. TavilySearchResults\n",
    "Что это:\n",
    "Инструмент поиска в интернете, подключаемый как tool_call.\n",
    "Работает через API сервиса Tavily.\n",
    "\n",
    "9. should_continue\n",
    "Что это:\n",
    "Функция, проверяющая, нужно ли что-то ещё сделать агенту (например, вызвать инструмент) или можно завершить работу (END).\n",
    "\n",
    "10. END\n",
    "Что это:\n",
    "Конечная точка в графе. Когда агент собрал все данные или завершил задачу, он переходит в END.\n",
    "\n",
    "11. is_complete()\n",
    "Что это:\n",
    "Функция-проверка: достаточно ли данных, чтобы завершить задачу. Можно встроить как проверку в граф, перед тем как перейти к END.\n",
    "\n",
    "12. bind_tools()\n",
    "Что это:\n",
    "Метод, который «привязывает» инструменты (поиск, вопросы, API) к языковой модели.\n",
    "Без этого LLM не узнает, что у него есть дополнительные способности.\n",
    "\n",
    "13. invoke()\n",
    "Что это:\n",
    "Метод запуска: можно вызвать как LLM, так и целый граф.\n",
    "graph.invoke({\"messages\": [...]}) — пример вызова агента.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b3fb4f-43a2-406a-a606-d903f18e8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    ".................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a8f978-6d33-465f-ba17-6b6e094633d3",
   "metadata": {},
   "source": [
    "Вот ссылки на официальную документацию по ключевым библиотекам и фреймворкам, которые используются при создании ИИ-агентов:\n",
    "\n",
    "🧩 1. LangChain\n",
    "Фреймворк для построения цепочек взаимодействия LLM с инструментами, памятью, документами и API.\n",
    "\n",
    "🔗 Документация: https://docs.langchain.com/\n",
    "\n",
    "🧠 Основные разделы: Chains, Agents, Tools, Memory, Retrieval, Output Parsers.\n",
    "\n",
    "🔁 2. LangGraph\n",
    "Расширение LangChain для создания графов состояния — помогает проектировать управляемые и повторяющиеся процессы с LLM.\n",
    "\n",
    "🔗 Документация: https://docs.langgraph.dev/\n",
    "\n",
    "📘 Полезное:\n",
    "\n",
    "https://docs.langgraph.dev/getting-started/introduction/\n",
    "\n",
    "https://docs.langgraph.dev/tutorials/build-an-agent/\n",
    "\n",
    "📚 3. LlamaIndex (ранее GPT Index)\n",
    "Инструмент для построения RAG (Retrieval-Augmented Generation) систем: работа с базами данных, PDF, сайтами и пр.\n",
    "\n",
    "🔗 Документация: https://docs.llamaindex.ai/\n",
    "\n",
    "🗃️ Используется для подключения внешних данных к LLM через индексы и движки поиска.\n",
    "\n",
    "🧑‍🤝‍🧑 4. CrewAI\n",
    "Фреймворк для создания мультиагентных систем: несколько агентов с ролями, заданиями и коммуникацией между ними.\n",
    "\n",
    "🔗 Документация: https://docs.crewai.com/\n",
    "\n",
    "📋 Фичи: роли агентов, планирование задач, совместное решение проблем.\n",
    "\n",
    "Если хочешь, могу сравнить их по функциям и сценариям применения (таблицей) или подобрать проектный шаблон для твоего учебника."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd0f195-493a-48f4-a55d-528a77942b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "/////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ceb557-8083-4e5e-a0b8-813d432f5be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Почему LangChain — основа:\n",
    "Центральный фреймворк для создания ИИ-агентов.\n",
    "\n",
    "Объединяет LLM (например, ChatGPT), инструменты (tools), память (memory), и цепочки (chains) в единый рабочий процесс.\n",
    "\n",
    "Поддерживает все основные компоненты агента:\n",
    "\n",
    "Tool calls\n",
    "\n",
    "Memory\n",
    "\n",
    "Prompt templates\n",
    "\n",
    "Agents (React, OpenAI functions, LangGraph)\n",
    "\n",
    "Output parsing\n",
    "\n",
    "Имеет огромное сообщество и активную разработку.\n",
    "\n",
    "Поддерживает интеграции с LangGraph, LlamaIndex, OpenAI, Hugging Face и др."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba01725a-6261-4949-979f-76b8d751ff77",
   "metadata": {},
   "source": [
    "Остальные библиотеки:\n",
    "Библиотека\tРоль\tКогда использовать\n",
    "LangGraph\tСтроит граф состояний (workflow)\tКогда нужен повторяющийся или контролируемый цикл работы агента\n",
    "LlamaIndex\tДоступ к внешним данным\tДля построения систем RAG (документы, базы, сайты)\n",
    "CrewAI\tМультиагентные сценарии\tКогда нужно несколько агентов с разными ролями"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0490d30-a127-430b-b93f-f120664ce7cc",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "LangChain — самая важная, потому что она \"скелет\" всей экосистемы.\n",
    "Остальные надстраиваются сверху:\n",
    "\n",
    "LangGraph для контроля процесса,\n",
    "\n",
    "LlamaIndex для подключения данных,\n",
    "\n",
    "CrewAI для командной работы агентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c4dd4-7606-45ba-978e-1152ef1bfc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "..............................................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a037116-98ca-4c3c-a0b7-377e843510cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129b39a-7b2c-40d1-8aa3-e866e3ac201e",
   "metadata": {},
   "source": [
    "Какая библиотека отвечает за создание цепочек и интеграцию с LLM, инструментами и памятью?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ab45fd-29e7-4fe4-90b8-28466b66b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LangGraph\n",
    "LangChain #\n",
    "LlamaIndex\n",
    "CrewAI\n",
    "OpenAI SDK\n",
    "Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1bb64-2af6-4f62-aaed-75cf9e7c5b93",
   "metadata": {},
   "source": [
    "LangChain — это основной фреймворк для создания ИИ-агентов. Он связывает LLM, инструменты, память, цепочки и агенты в единую систему. Без него другие библиотеки редко работают изолированно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d3a1ff-984e-4b02-86bd-d14b2eef3cef",
   "metadata": {},
   "source": [
    "LangChain — это самая фундаментальная библиотека для построения ИИ-агентов на Python. Она объединяет в себе несколько ключевых компонентов: языковые модели (LLM), внешние инструменты (tools), память (memory), цепочки шагов (chains), а также интерфейсные слои, такие как промпт-шаблоны (prompt templates), кастомные output-парсеры и агенты.\n",
    "LangChain действует как своего рода «организм» агента:\n",
    "Модель (LLM) — это мозг.\n",
    "Инструменты — это руки и ноги, которыми агент может действовать во внешнем мире.\n",
    "Память — это опыт \n",
    "Prompt-шаблоны — способ агенту сформулировать свои мысли.\n",
    "Output parsers — способ структурировать свои ответы.\n",
    "Agents — движки логики принятия решений.\n",
    "Без LangChain координировать работу всего этого приходилось бы вручную. Эта библиотека обеспечивает единый API, позволяет использовать множество разных моделей (OpenAI, Anthropic, HuggingFace), подключать произвольные инструменты, строить многоступенчатые цепочки шагов и запускать агентов с разной логикой — от rule-based до ReAct.\n",
    "Она также прекрасно сочетается с другими библиотеками:\n",
    "LangGraph добавляет структуру выполнения в виде графа.\n",
    "LlamaIndex позволяет агенту «читать» и извлекать информацию из внешних источников.\n",
    "CrewAI организует работу нескольких агентов с ролями и координацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2199c0-1805-4e4c-8d6e-74d8fc4ded73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e138fb-7a08-44c7-bda6-e00d9a27edce",
   "metadata": {},
   "source": [
    "Какая библиотека отвечает за построение графа выполнения ИИ-агента (узлы, переходы, состояния)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61dea87-6958-490f-b4d6-d6090de5cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LangChain\n",
    "LangGraph #\n",
    "LlamaIndex\n",
    "CrewAI\n",
    "NetworkX\n",
    "Chainlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda3b9fc-e523-4afd-af94-a95d32782fd2",
   "metadata": {},
   "source": [
    "LangGraph позволяет строить графы выполнения для агентов: каждый шаг — это узел, а переходы между ними — логика решения. Он помогает управлять циклом LLM → инструмент → LLM и отслеживать состояние."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ca31d-ecde-48e1-a4f3-6dab4b315ad5",
   "metadata": {},
   "source": [
    "LangGraph — это библиотека, которая расширяет возможности LangChain, позволяя описывать агентные системы в виде графа. В такой структуре каждый узел (node) — это действие (например, вызов LLM или инструмента), а переходы (edges) — это логика перехода к следующему действию на основе состояния (state).\n",
    "Пример:\n",
    "Узел 1: LLM задаёт вопрос\n",
    "Узел 2: Инструмент получает ответ\n",
    "Условный переход: если данных достаточно — завершить, иначе — вернуться к LLM\n",
    "Это особенно удобно, если:\n",
    "Агент делает несколько шагов и принимает решения в процессе\n",
    "Нужно выполнять циклы (LLM → tool → LLM)\n",
    "Требуется гибкая логика: завершение, перезапуск, ожидание пользователя\n",
    "LangGraph также помогает структурировать state, передавать данные между узлами и логично отслеживать, где находится агент. Он делает логику агента более читаемой, масштабируемой и отлаживаемой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f97c2-599b-47a0-9516-3d528e87e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#47"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a2ec3d-7292-4141-88c7-6044f3c204f1",
   "metadata": {},
   "source": [
    "Какая библиотека используется для поиска, извлечения и вставки контекста в LLM из внешних источников (документы, базы)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac6d468-a9ff-4aca-9e66-09512ce3d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "LangChain\n",
    "LangGraph\n",
    "LlamaIndex  #\n",
    "CrewAI\n",
    "Faiss\n",
    "Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de41ba7-d39f-41a1-b922-c52f05ec00ec",
   "metadata": {},
   "source": [
    "LlamaIndex (ранее GPT Index) — библиотека для структурирования и подключения внешней информации к агенту. Она позволяет извлекать данные из PDF, баз данных, сайтов и передавать LLM релевантный контекст (RAG)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf7bbc-431c-43d8-9d8e-6830bda597de",
   "metadata": {},
   "source": [
    "LlamaIndex специализируется на RAG (Retrieval-Augmented Generation), т.е. обогащении ответа LLM внешней информацией. Агент может быть подключён к PDF-файлам, SQL-базам, API, Notion, HTML-страницам и другим источникам. В момент запроса агент сначала ищет информацию в этих источниках, затем передаёт LLM только релевантное.\n",
    "\n",
    "Основные возможности:\n",
    "\n",
    "Построение индексов из документов\n",
    "\n",
    "Использование векторов (с Faiss, Weaviate, Pinecone)\n",
    "\n",
    "Автоматический поиск нужного контекста\n",
    "\n",
    "Интеграция с LangChain и LangGraph\n",
    "\n",
    "Например, юрист-агент может:\n",
    "\n",
    "Найти нужную статью закона в PDF\n",
    "\n",
    "Подставить её в промпт LLM\n",
    "\n",
    "Дать более точный ответ, основанный на внешней информации\n",
    "Без LlamaIndex LLM работает только с тем, что «знает» до 2023 года. С ним — он может использовать любые ваши данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2cc082-13ac-4ab0-aaea-6581402c2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#48"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25141037-7cf0-438c-870c-50c4b1164061",
   "metadata": {},
   "source": [
    "Какая библиотека отвечает за координацию нескольких агентов с разными ролями (например, исследователь, писатель, критик)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a38db4c-bea1-4268-b7c3-5793121056d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LangChain\n",
    "LangGraph\n",
    "LlamaIndex\n",
    "CrewAI  #\n",
    "AgentOps\n",
    "OpenAgents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fde677-d090-48e1-9cb9-7450774b510f",
   "metadata": {},
   "source": [
    "CrewAI позволяет запускать команду агентов с разными ролями и задачами. Она координирует выполнение шагов, взаимодействие между агентами и порядок их вызовов, формируя цепочку ролей и взаимодействий."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b42312-aefa-44e6-a2c0-b47fb7bca49a",
   "metadata": {},
   "source": [
    "CrewAI — это библиотека, созданная для управления мультиагентными системами. В отличие от LangChain, который управляет одним агентом, CrewAI позволяет определить несколько агентов, каждый со своей ролью, инструкцией, и набором инструментов.\n",
    "Типичный пример:\n",
    "Агент-исследователь ищет информацию\n",
    "Агент-аналитик обобщает и выводит инсайты\n",
    "Агент-писатель формирует финальный текст\n",
    "CrewAI позволяет:\n",
    "Назначать роли и цепочки взаимодействия\n",
    "Делать асинхронные или последовательные команды\n",
    "Использовать общую память между агентами\n",
    "Настраивать условия завершения или передачи управления\n",
    "CrewAI не заменяет LangChain, а строится на нём — ты можешь использовать LangChain-агентов внутри CrewAI-команд. Это отличный инструмент для построения сложных рабочих процессов, особенно если ты хочешь имитировать коллективную работу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49970a8f-13fa-42ff-9660-d88cad21ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "🔹архитектура агента,\n",
    "🔹 его жизненный цикл,\n",
    "🔹 типы агентов (реактивные, рефлексивные, планирующие),\n",
    "🔹 агенты с памятью,\n",
    "🔹 одиночные против мультиагентных систем\n",
    "🔹 роль обучения (RL, RAG, few-shot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc20c17-4eb3-4fbd-bb66-0e610de80006",
   "metadata": {},
   "outputs": [],
   "source": [
    "как создавать агента руками (в коде),\n",
    "\n",
    "какие есть готовые паттерны (AgentExecutor, Graph, Tools),\n",
    "\n",
    "как использовать state, memory, prompt engineering на практике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0f6f7-a400-4edc-b82a-c508d81d9bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#архитектура агента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946ffe7-111c-48cc-bac6-38df7414885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b51791-e0b1-4383-bf6b-5bf49251556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что из перечисленного лучше всего описывает архитектуру ИИ-агента?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a61c26-8284-4bb7-b29b-1abfcd9a8c2c",
   "metadata": {},
   "source": [
    "Последовательность промптов, отправляемых в LLM\n",
    "Способ хранения данных в базе\n",
    "Структура взаимодействия между LLM, инструментами, памятью и логикой действий #\n",
    "Интерфейс чата для пользователя\n",
    "Алгоритм генерации текста GPT-модели\n",
    "Способ запуска кода в облаке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b316e-7f6f-45ed-9b75-82667a28685c",
   "metadata": {},
   "source": [
    "Архитектура агента — это схема, по которой взаимодействуют LLM, инструменты (tools), память (memory) и управляющая логика (например, граф), обеспечивая выполнение задач и адаптацию агента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6601d0-364d-4914-892f-d1003d817fd4",
   "metadata": {},
   "source": [
    "Архитектура ИИ-агента описывает его внутреннюю организацию и принципы работы. Это не просто LLM с промптом, а полноценная система, где несколько компонентов работают вместе:\n",
    "\n",
    "🔹 LLM (Large Language Model) — мозг агента, генерирующий действия, ответы и tool_calls.\n",
    "🔹 Инструменты (tools) — каналы выхода агента во внешний мир: интернет-поиск, взаимодействие с пользователем, API-вызовы.\n",
    "🔹 Память (memory) — возможность хранить факты и историю взаимодействий между сессиями, чтобы агент мог \"помнить\" прошлые события.\n",
    "🔹 Управляющая логика (например, граф в LangGraph) — определяет, какие шаги выполняет агент, какие узлы посещает, когда завершает работу.\n",
    "\n",
    "Вместе эти элементы формируют архитектуру, позволяющую агенту принимать решения, собирать данные, задавать вопросы и выполнять действия. Простой чат-бот — это ещё не агент. Агент — это система с контекстом, намерением, планом и способами достижения цели. Разработка архитектуры включает выбор нужных компонентов и настройку их взаимодействия.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf9ab9-2f19-4db5-abfd-70acbd9efc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ce1a8-f842-4d7a-bcb2-69ac9636f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "Какой шаг НЕ входит в типичный жизненный цикл ИИ-агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b421a2f-55b5-4ab7-9cd2-711ce07eb0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Получение входного запроса от пользователя\n",
    "Анализ и выбор следующего действия\n",
    "Генерация и выполнение tool_call\n",
    "Обновление состояния агента\n",
    "Случайная генерация финального ответа  #\n",
    "Проверка, достигнута ли цель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecf3b8c-6a50-491e-a19c-7cab5a9a5950",
   "metadata": {},
   "source": [
    "Случайная генерация ответа не входит в жизненный цикл ИИ-агента. Агент действует осмысленно: получает запрос, выбирает действия, вызывает инструменты, обновляет состояние и проверяет, достиг ли цели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241fc793-daa6-4e4d-a44b-07bb8216e011",
   "metadata": {},
   "source": [
    "Жизненный цикл ИИ-агента — это повторяющийся процесс, по которому агент обрабатывает задачи. Он включает следующие ключевые этапы:\n",
    "Получение входных данных: Агент получает запрос пользователя, информацию от внешней системы или результат предыдущей итерации.\n",
    "Оценка текущего состояния: Агент анализирует контекст, историю сообщений, что уже собрано, и определяет, что нужно делать дальше.\n",
    "Выбор действия: На основе текущего состояния и промпта LLM предлагает, что делать — обратиться к инструменту, задать вопрос, завершить работу.\n",
    "Вызов tool_call: Если нужно, агент вызывает инструмент (например, поиск, парсер, API).\n",
    "Обновление состояния (state): Результат tool_call или ответ пользователя записывается в историю.\n",
    "Проверка завершения: Агент оценивает, достаточно ли данных. Если да — завершает работу, если нет — продолжает цикл.\n",
    "Вариант E (случайная генерация финального ответа) — ошибочный. Агент не действует случайно. Даже если модель не всегда оптимальна, её поведение формируется промптом, историей и логикой переходов. Он не \"угадывает\", а планирует.\n",
    "Таким образом, жизненный цикл агента — это управляемый процесс, где на каждом шаге проверяется логика, цель и полнота данных. Это и отличает агента от просто LLM-сессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bc2b73-dd01-44a4-b8ca-9238cf72930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#51"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc05d2ee-0bed-442c-b08b-676bfd03f07f",
   "metadata": {},
   "source": [
    "Какой агент лучше всего описывает поведение: “Получил команду — немедленно действует, не запоминая контекст”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceddd2c-4026-486a-98a3-c68a32d97773",
   "metadata": {},
   "outputs": [],
   "source": [
    "Планирующий агент\n",
    "Рефлексивный агент\n",
    "Реактивный агент  #\n",
    "Агент с RAG\n",
    "Агент с памятью\n",
    "Мультиагентная система"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6648c4cf-5be2-4f4e-bbdf-6a710176d38b",
   "metadata": {},
   "source": [
    "Реактивный агент действует сразу, как только получает команду, и не учитывает историю или глобальный план. Он не использует память и не планирует будущие шаги. Это наименее “осознанный” тип агента.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f92f1c2-c283-41d5-a439-67477f899544",
   "metadata": {},
   "source": [
    "Типы ИИ-агентов различаются по уровню “осознанности” и способности к планированию.\n",
    "Разберём:\n",
    "Реактивный агент — самый простой. Он действует моментально, по шаблону: “если вход → тогда действие”. Нет памяти, нет анализа истории, нет предсказаний. Хорош для простых задач: например, автоматическая сортировка писем или ответы по шаблону.\n",
    "Рефлексивный агент — использует ограниченный контекст. Он может учитывать текущую ситуацию или недавние сообщения. Например, диалоговый агент, который отвечает на вопросы, учитывая текущую тему, но не помнит, о чём шла речь вчера.\n",
    "Планирующий агент — строит стратегию на несколько шагов вперёд. Он может принимать промежуточные решения, оценивать состояние цели и корректировать поведение. Например, агент, оформляющий документы по этапам, проверяя полноту данных.Агент с RAG — подключает внешнюю базу знаний: ищет нужные факты и включает их в ответ. Это не самостоятельный тип, а надстройка над рефлексивным или планирующим агентом.\n",
    "Агент с памятью — хранит историю задач, контекст пользователя, может возвращаться к старым разговорам. Это важно для персонализации или длительных процессов.\n",
    "Мультиагентная система — не отдельный агент, а группа, где каждый выполняет свою роль. Один может искать данные, другой — писать тексты, третий — проверять на ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7abf4b-1eeb-4c5f-8580-012d0e6895dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0019dc16-1e1b-4045-98d5-e38f3253843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "В каком случае мультиагентная система предпочтительнее одиночного агента?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eca40c-e720-43d6-bee1-c291467f1be4",
   "metadata": {},
   "source": [
    "Когда задача проста и не требует инструментов\n",
    "Когда нужно выполнить одну инструкцию быстро\n",
    "Когда один агент должен вести беседу\n",
    "Когда задача состоит из нескольких ролей и этапов  #\n",
    "Когда память агента отключена\n",
    "Когда нужен только поиск в интернете"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463aa058-daa1-4b1c-9c8f-7487b83c4147",
   "metadata": {},
   "source": [
    "Мультиагентная система нужна, когда задачу нельзя решить одним агентом — например, требуется разделение на этапы, роли, компетенции. Тогда каждый агент специализируется и передаёт результат следующему."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d26c8e-bc9e-45f1-8df4-93181e85d110",
   "metadata": {},
   "source": [
    "Мультиагентная система — это не один агент, а координированная команда агентов, где каждый выполняет свою функцию. Это особенно важно, когда:\n",
    "Задача многоэтапная: например, сначала нужно собрать данные, потом — сформировать документ, потом — отправить его.\n",
    "Задача требует разных навыков: один агент хорошо обрабатывает естественный язык, другой — работает с базой данных, третий — выполняет действия через API.\n",
    "Требуется разделение ответственности: например, “ассистент-юрист” и “ассистент-писатель” — один собирает факты, другой пишет жалобу.\n",
    "В таких системах часто используются обмен сообщениями, общее состояние и управление ролями. Примеры фреймворков: CrewAI, AutoGen, LangGraph с кастомной логикой.\n",
    "Рассмотрим контр-примеры:\n",
    "A. Простая задача — одному агенту проще.\n",
    "B. Одна инструкция — мультиагентность избыточна.\n",
    "C. Ведение беседы — обычно требует одного агента с памятью.\n",
    "E. Память отключена — нет смысла в координации.\n",
    "F. Только поиск — справится один агент с инструментом.\n",
    "➡ Правильный вариант — D: сложные задачи с распределением по ролям и этапам — это домен мультиагентных систем.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927dbd7-bb21-492d-a84c-1f37b8f72f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a9ed87-0a93-48d2-874f-587a45152f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "В каком случае агенту обязательно нужна память?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03081ba7-678b-4eaa-8bf9-0dd5f5fd9c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Когда задача требует много шагов с сохранением контекста #\n",
    "Когда агент отвечает на один короткий вопрос\n",
    "Когда поиск информации выполняется сразу\n",
    "Когда используется системный промпт\n",
    "Когда агент работает с фиксированным текстом\n",
    "Когда все данные заранее известны"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab82c0db-587a-4c7e-aa4c-6f2a7c045a65",
   "metadata": {},
   "source": [
    "Память агенту нужна, если он выполняет сложные задачи с несколькими шагами, где нужно помнить прошлые действия, ответы пользователя или результаты инструментов. Без памяти он будет «забывать» и переспрашивать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b61c8-e9a7-4a18-a13b-381828cce568",
   "metadata": {},
   "source": [
    "Память в агентных системах позволяет сохранить и использовать информацию, полученную на предыдущих этапах. Это особенно важно в задачах, где:\n",
    "Пользователь взаимодействует с агентом долго, передавая данные постепенно (например, поочередно отвечает на вопросы).\n",
    "Агент должен помнить уже полученную информацию (например, уже известное имя клиента или предыдущие ошибки).\n",
    "Задача требует планирования, где необходимо помнить цели, текущий прогресс и частичные решения.\n",
    "Механизмы памяти могут быть разными:\n",
    "MessagesState — сохранение истории сообщений (как в LangGraph).\n",
    "ConversationBufferMemory, VectorStoreMemory — специальные структуры из LangChain.\n",
    "Связка с базами данных или long-term memory-хранилищами (например, через RAG).\n",
    "\n",
    "Контр-примеры:\n",
    "\n",
    "B. Один короткий вопрос — память не требуется.\n",
    "\n",
    "C. Поиск выполняется мгновенно — результат не нужно помнить.\n",
    "\n",
    "D. Системный промпт влияет на стиль и поведение, но не связан с памятью.\n",
    "\n",
    "E. Фиксированный текст — можно сразу использовать.\n",
    "\n",
    "F. Заранее известные данные — не требуется их накапливать по ходу.\n",
    "\n",
    "➡ Правильный вариант — A: именно в многошаговых задачах память критична для качества и автономности агента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a330643-7f08-4252-b310-5a00874cdd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d270c9-f6e9-4222-af0b-d84b915a3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "Какую роль играет память в многошаговом диалоге агента с пользователем?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055c8f1-f973-4753-ae95-a9596075488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Позволяет агенту возвращаться к предыдущим шагам #\n",
    "Хранит HTML-шаблоны для интерфейса\n",
    "Используется только для хранения токенов\n",
    "Ускоряет ответы, заменяя нейросеть\n",
    "Хранит системный промпт\n",
    "Помогает не переспрашивать то, что уже было сказано  #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af20bb4-b2d9-47c5-9d8e-c9f3f439e75a",
   "metadata": {},
   "source": [
    "Память в многошаговом диалоге нужна, чтобы не переспрашивать одно и то же, учитывать уже полученные данные и возвращаться к ним при необходимости. Это ключ к построению диалогов, похожих на человеческие."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43d1214-7954-4f8a-9bae-1e0dd0eece3c",
   "metadata": {},
   "source": [
    "Память в агентной системе выполняет функцию долгосрочного или краткосрочного хранения информации, чтобы обеспечить связное, логичное и эффективное взаимодействие с пользователем. Особенно это важно в многошаговых диалогах, где:\n",
    "Агент задаёт серии уточняющих вопросов, и ему нужно помнить, что уже получено (например: имя, дата, адрес).\n",
    "Агент может возвращаться к предыдущим шагам, повторно использовать информацию или напоминать о ней пользователю.\n",
    "Важно не задавать повторяющиеся вопросы, чтобы не раздражать пользователя.При использовании внешних инструментов (поиск, API) память позволяет объединять результаты в единую цепочку.\n",
    "\n",
    "❌ Варианты B, C, D, E ошибочны:\n",
    "\n",
    "B. HTML-шаблоны не относятся к памяти агента.\n",
    "\n",
    "C. Токены — это единицы текста, память хранит смыслы, а не только токены.\n",
    "\n",
    "D. Память не заменяет нейросеть, а дополняет её.\n",
    "\n",
    "E. Системный промпт задаётся отдельно и не является частью динамической памяти.\n",
    "\n",
    "✅ Правильные ответы — A и F.\n",
    "Они отражают суть того, зачем агенту память: связывать диалог, избегать повторов, действовать последовательно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b04c29a-60ad-49ae-8f8b-7b1106536ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd801a7-2f58-4781-bd28-f873d96849f6",
   "metadata": {},
   "source": [
    "Какую структуру чаще всего использует агент для хранения состояния (state), включая память, историю сообщений и промежуточные данные?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1468b08-c0a8-438e-800b-de203969527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Список строк\n",
    "Класс AgentMemoryHandler\n",
    "JSON-объект или словарь с ключами  #\n",
    "SQLite база данных\n",
    "Константная строка в prompt\n",
    "Отдельные .txt-файлы для каждого действия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af15a9c-65d8-4183-9d49-d43f34d2e59b",
   "metadata": {},
   "source": [
    "Агенты чаще всего используют структуру словаря (или JSON-подобный формат), чтобы отслеживать сообщения, вызовы инструментов и другие переменные. Это позволяет гибко передавать данные между нодами и компонентами агента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad066c87-7c16-4c2d-a790-ef47dbcaae60",
   "metadata": {},
   "source": [
    "В архитектуре ИИ-агентов, особенно тех, что реализованы через LangGraph, LangChain или аналогичные фреймворки, память и текущее состояние агента хранятся в виде структуры данных, напоминающей словарь (dict) или JSON-объект. Это решение объясняется гибкостью и читаемостью формата.\n",
    "Словарь позволяет легко сохранять и извлекать ключевые элементы состояния, такие как:\n",
    "\"messages\" — история всех сообщений между агентом, пользователем и инструментами.\n",
    "\n",
    "\"tool_results\" — результаты вызова внешних инструментов.\n",
    "\n",
    "\"step_count\" — количество итераций, которые агент прошёл.\n",
    "\n",
    "\"user_inputs\" — сохранённые ответы пользователя.\n",
    "\n",
    "Любые дополнительные ключи, которые определяются в логике графа.\n",
    "Такая структура идеально подходит для передачи данных между нодами в графе LangGraph. Каждая нода может изменять или добавлять ключи, а затем передавать их дальше. Например, нода gather_data_node может добавить результат от LLM, а ToolNode — записать в тот же state результат запроса через API.Кроме того, структура словаря хорошо совместима с сериализацией — её можно легко сохранить, передать по сети или логировать. Она также позволяет реализовать механизм \"проверки полноты\" (is_complete) — достаточно пройтись по ключам и убедиться, что все нужные данные получены.\n",
    "Хотя возможно использовать другие формы хранения (например, базы данных или внешние файлы), словари остаются универсальным и предпочтительным выбором, особенно в proof-of-concept или MVP системах, где важна скорость итерации и простота реализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c630c59-6ced-4809-84e3-3596c114a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa46e2-a699-4ef3-a8f5-8d4b18170d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Какое ключевое различие между временной и долговременной памятью агента?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a48a2a-bb19-4295-9622-9898e5ec7ad1",
   "metadata": {},
   "source": [
    "Временная память хранится на сервере, а долговременная — локально\n",
    "Временная память включает только последние действия, долговременная — знания и опыт #\n",
    "Временная память обновляется вручную, долговременная — автоматически\n",
    "Временная память используется в RAG, долговременная — в RL\n",
    "Временная память — это база данных, долговременная — JSON\n",
    "Временная память доступна пользователю, долговременная — нет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7f9048-9c40-4da1-a3b8-57c32ba5ea8d",
   "metadata": {},
   "source": [
    "Временная память (short-term) содержит текущую историю сообщений, актуальную на время сессии. Долговременная память (long-term) хранит факты, предпочтения и выводы, которые агент может использовать через длительное время и в других задачах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef175f39-4677-4cba-95c6-42dc6f98d082",
   "metadata": {},
   "source": [
    "В системах ИИ-агентов часто используется концепция двухуровневой памяти: временной и долговременной. Они выполняют разные функции и отвечают за разные горизонты \"вспоминания\".\n",
    "Временная память — это то, что агент \"помнит\" в пределах одной сессии или диалога. Это может быть:\n",
    "история сообщений между пользователем и LLM,\n",
    "текущие шаги агента (tool_calls, промежуточные выводы),\n",
    "результаты поиска и вызовов API.\n",
    "Она доступна в структуре state (например, MessagesState) и используется, чтобы сохранить контекст и последовательность шагов. Однако при завершении сессии или переходе в другую задачу временная память часто сбрасывается.\n",
    "Долговременная память, наоборот, сохраняется между сессиями. Её можно реализовать через векторные базы данных (например, FAISS, Chroma, Weaviate), SQL-хранилища, или даже внешние документы. В неё записываются:ключевые факты, которые пользователь сообщил агенту (например, \"меня зовут Иван\", \"я работаю юристом\"),\n",
    "знания, извлечённые из текста или веб-страниц,\n",
    "ранее сделанные выводы или рассуждения.\n",
    "Долговременная память — это основа обучающегося агента, способного адаптироваться к пользователю, вспоминать предпочтения, восстанавливать контекст даже после перерыва. Она также используется в RAG (Retrieval-Augmented Generation) — агент вспоминает релевантные документы и подставляет их в контекст перед генерацией.\n",
    "Разделение памяти на кратко- и долгосрочную позволяет строить более реалистичную модель поведения, в которой агент не \"забыл всё\", но и не \"переполнен\" лишней информацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13144316-6a0d-4bc1-ae17-3d4051533a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c4d88-6432-49be-990a-b3f5522d66c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Каким образом LLM-агент обычно обновляет свою долговременную память?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31db23f7-b330-49ec-b164-14d285ac6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Запоминает каждое сообщение из чата автоматически\n",
    "Использует специальный инструмент или функцию записи  #\n",
    "Преобразует всю память в JSON и сохраняет файл\n",
    "Через вручную прописанные инструкции администратора\n",
    "Хранит всё в переменных Python, доступных в любой момент\n",
    "Просто обращается к cache и сам определяет, что сохранить"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a3aa87-733c-423f-9501-cb60d8e28e1b",
   "metadata": {},
   "source": [
    "LLM-агенты не сохраняют знания сами. Чтобы сохранить информацию в долговременную память, они используют инструменты: например, write_memory() или внешние базы, куда записываются нужные данные на основе внутренней логики.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32408a4-7354-41ca-8576-5434c035710d",
   "metadata": {},
   "source": [
    "Долговременная память в ИИ-агенте — это механизм, который позволяет сохранять и извлекать значимые данные между сессиями. Однако Large Language Models (LLMs), включая GPT, не могут сами запоминать информацию. Им необходимо поручить это действием через агентную архитектуру.\n",
    "В агентных системах, таких как LangGraph или CrewAI, долговременная память реализуется через внешние хранилища — векторные базы данных (Chroma, FAISS, Pinecone), документы, SQL или KV-хранилища. Чтобы что-то туда записать, используется инструмент или специализированный узел в графе — например, write_to_memory() или store_fact().\n",
    "Этот инструмент обычно вызывается агентом на основе логики. Например:\n",
    "Агент получает от пользователя важную информацию — \"Я работаю в компании ООО «Спорт Форум»\".\n",
    "Затем агент определяет, что это факт, который стоит сохранить.Агент вызывает store_fact(content=\"Пользователь работает в ООО «Спорт Форум»\")\n",
    "Эта информация сохраняется в базе памяти.\n",
    "Позже, при новых задачах, другая часть графа или другой агент может вызвать retrieve_memory(query=\"где работает пользователь\"), чтобы восстановить этот факт и использовать его в ответе или принятии решения.\n",
    "Важно понимать: память не сохраняется автоматически. Если не прописать механизм сохранения — агент \"забудет\" даже важную информацию после завершения сессии.\n",
    "Также сохранение можно \"научить\" быть контекстным: с помощью промпта агенту объясняют, какие типы данных он должен сохранять — имена, адреса, предпочтения, факты, выводы и т.д.\n",
    "Такой подход делает агента способным к обучению, накоплению знаний и персонализации поведения.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41aefa0-8416-4e8b-b372-48be109d60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070b39b-9c3e-4064-abc0-b7060a8b1c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Как использование памяти влияет на поведение и эффективность LLM-агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaeaea5-db7d-458e-b6fe-672359f51a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Делает агента медленнее, но безопаснее\n",
    "Позволяет агенту учитывать прошлый опыт  #\n",
    "Ограничивает количество возможных действий\n",
    "Не имеет значения, если используется GPT-4\n",
    "Увеличивает объём оперативной памяти компьютера\n",
    "Заменяет все системные промпты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45f636-2ed0-4dcc-8751-e83441f7b098",
   "metadata": {},
   "source": [
    "Память позволяет агенту учитывать предыдущие взаимодействия, факты и предпочтения, что делает поведение более последовательным, адаптивным и персонализированным — особенно при решении сложных или многосессионных задач."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813aef72-c2f2-44df-b2bd-27d57653947d",
   "metadata": {},
   "source": [
    "Память играет ключевую роль в архитектуре LLM-агентов, особенно когда они работают в долгосрочных сценариях, где важно не только моментальное понимание задачи, но и учёт накопленного контекста.\n",
    "Когда агент запоминает:\n",
    "Факты о пользователе (например, имя, адрес, цели)\n",
    "Историю задач (что уже обсуждалось, что было сделано)\n",
    "Контекст решений (почему выбрано то или иное действие)\n",
    "— он может принимать более точные, логичные и согласованные решения.\n",
    "Пример: если в прошлом пользователь сказал, что живёт в Москве, и позже спрашивает: \"Где ближайший магазин?\", агент с памятью сможет уточнить результат для Москвы, а не переспросить снова. Без памяти этого не произойдёт.Также это важно в мультиагентных системах. Один агент может передать знание другому (через общее хранилище), и они будут работать как единая система, а не как изолированные боты.\n",
    "Кроме того, память помогает избежать:\n",
    "Повторных вопросов\n",
    "Сбивчивых ответов\n",
    "Забывания важных вводных\n",
    "Наконец, память открывает возможность персонализации: агент может адаптироваться под стиль общения пользователя, его предпочтения и поведение, как это делают реальные ассистенты.\n",
    "Однако всё это возможно только при правильно настроенной структуре памяти и логике её использования: простого хранения недостаточно — нужна стратегия извлечения и применения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1cc056-5706-49db-8b2f-ed59b3a449e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d5f11-cb8f-4593-bb3c-784b9167d3a8",
   "metadata": {},
   "source": [
    "Какой из перечисленных вариантов наилучше описывает разницу между краткосрочной и долговременной памятью в архитектуре ИИ-агента?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186538be-d013-4d97-9ca2-7fd500475215",
   "metadata": {},
   "source": [
    "Краткосрочная память сохраняет весь код, долговременная — только действия\n",
    "Краткосрочная память хранит сообщения в сессии, долговременная — сохраняет знания между сессия#\n",
    "Краткосрочная используется для хранения API-ключей, долговременная — для вызова инструментов\n",
    "Краткосрочная память отвечает за физическую память, долговременная — за виртуальную\n",
    "Краткосрочная память запоминает ошибки, долговременная — исправления\n",
    "Они отличаются только размером, но выполняют одну и ту же функцию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a2dc8-3604-40b2-b534-3d6d6ab0558b",
   "metadata": {},
   "source": [
    "Краткосрочная память — это текущая история общения в одной сессии. Долговременная — это сохранённые факты и выводы, доступные агенту даже после завершения сессии. Она используется, чтобы \"помнить\" между запусками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196dace-469d-4e77-8e43-1eaf3a0bbf33",
   "metadata": {},
   "source": [
    "В агентных системах память разделяется на два ключевых типа — краткосрочную и долговременную. Это деление вдохновлено когнитивной архитектурой человека.\n",
    "Краткосрочная память (short-term memory):\n",
    "Это всё, что агент \"держит в голове\" прямо сейчас — обычно это история текущей сессии или диалога. Она состоит из:\n",
    "Предыдущих сообщений пользователя и агента\n",
    "Последних шагов в цепочке логики\n",
    "Ответов инструментов (например, результатов поиска)\n",
    "Она очищается после завершения сессии. Применяется в LangGraph как MessagesState или через встроенную историю сообщений в LangChain и других фреймворках.\n",
    "Долговременная память (long-term memory):\n",
    "Это память, которую агент сохраняет на постоянной основе, и может обращаться к ней при необходимости — даже спустя дни. Она может включать:Биографию пользователя\n",
    "Предпочтения, стили общения\n",
    "Выводы и промежуточные знания\n",
    "Историю завершённых дел\n",
    "Долговременная память чаще всего реализуется через внешние хранилища (векторные БД, файлы, базы данных), которые агент запрашивает, когда нужно.\n",
    "Зачем это важно?\n",
    "Без краткосрочной памяти агент теряет контекст диалога.\n",
    "Без долговременной памяти агент не \"помнит\", кто вы, ваши прошлые задачи и цели.\n",
    "Правильное сочетание этих типов памяти делает агента по-настоящему интеллектуальным и персонализированным.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ee0373-2c1d-4905-a694-9788b9962cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f0b16-ed0a-42cc-ae2f-dce0ff4f49f7",
   "metadata": {},
   "source": [
    "В какой форме чаще всего агент хранит данные в state для взаимодействия между узлами в LangGraph или другой агентной архитектуре?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d6b05-9ce4-4ff2-a8d6-7cf14b5b9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "В виде текстового файла .txt\n",
    "Через глобальные переменные Python\n",
    "В виде структурированного словаря (dict) с ключами #\n",
    "Только в базе данных\n",
    "Через вложенные HTML-страницы\n",
    "Агент не использует хранилище, всё передаётся устно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f82b08-81c7-4261-ab57-7e9b348e393f",
   "metadata": {},
   "source": [
    "Агенты используют словари (dict) как основу состояния (state). Это позволяет передавать между узлами структурированные данные: сообщения, результаты инструментов, флаги завершения и т. д. Такой формат удобен и гибок."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf614f-6e1b-482e-b2d7-a3548668ed0f",
   "metadata": {},
   "source": [
    "В архитектуре агентных систем (например, LangGraph, LangChain) основной способ хранения текущего состояния агента — это словарь (dict), в который можно помещать любые данные, необходимые для выполнения задач.\n",
    "Что такое state?\n",
    "Это внутренний контейнер агента, в который записываются и из которого читаются данные при прохождении узлов (нод) графа.\n",
    "Почему именно словарь?\n",
    "Словарь (dict) — это удобная структура данных, которая:\n",
    "Читается и записывается быстро\n",
    "Поддерживает ключи и значения (легко находить нужное)\n",
    "Гибко расширяется: можно добавлять новые ключи, не нарушая логику\n",
    "Подходит для JSON-сериализации (если нужна внешняя передача или логирование) Что может храниться в state?\n",
    "История сообщений (messages)\n",
    "Последний вызов инструмента\n",
    "Переменные, управляющие логикой графа (например, is_complete)\n",
    "Результаты поиска или взаимодействия с пользователем \n",
    "Как передаётся информация?\n",
    "Каждая нода (node) в графе получает на вход state, может его прочитать, изменить и вернуть. Следующая нода получит уже обновлённый state. Это делает возможной пошаговую обработку, условные переходы и сохранение промежуточных результатов.\n",
    "Связь с памятью:\n",
    "Иногда часть state называют краткосрочной памятью, но важно понимать, что state — это не просто история сообщений. Это контейнер для всей логики, которую использует агент на текущем этапе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df845c-d1ad-4083-b2a0-395c6cf3e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"messages\": [...],\n",
    "    \"company_data\": {...},\n",
    "    \"client_info\": {...},\n",
    "    \"tool_call_result\": {...},\n",
    "    \"is_complete\": False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369c4a6-0189-4ec3-8087-a6501dcd250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#61"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9d911-97a9-4760-87eb-f012cd347395",
   "metadata": {},
   "source": [
    "Как именно данные передаются между различными нодами (узлами) в агентном графе, например, в LangGraph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01394ef-ac21-4fbd-b13c-61bc6b33d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "Через глобальные переменные Python\n",
    "B. Сохраняются во внешнем файле\n",
    "C. Автоматически переносятся через state  #\n",
    "D. Каждая нода использует свою независимую память\n",
    "E. Передаются по email между узлами\n",
    "F. Хранятся на стороне пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca0b8a-71b9-4128-8f01-df083e0400be",
   "metadata": {},
   "source": [
    "Передача данных между нодами происходит через state — это единая структура, которую каждая нода может читать и изменять. Обновлённый state автоматически передаётся следующей ноде по логике графа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f26794-fa3c-469a-8642-cef0d9c8b90f",
   "metadata": {},
   "source": [
    "В агентных системах, основанных на графах (например, LangGraph), данные передаются между узлами (нодами) с помощью общей структуры, называемой state (состояние). Это центральный элемент, который позволяет агенту сохранять и обновлять знания в ходе своей работы.\n",
    "State — это, как правило, словарь (dict) или объект, содержащий все необходимые данные о текущем процессе. В него входят:\n",
    "История общения (messages) между пользователем, LLM и инструментами;\n",
    "Данные, полученные от пользователя (input_data);\n",
    "Результаты работы инструментов (tool_call_results);\n",
    "Флаги завершения (is_complete, execution_status) и другие рабочие параметры. Каждая нода получает state как входной параметр, может читать и модифицировать его. Когда нода завершается, она возвращает обновлённое состояние, которое передаётся дальше — в следующую ноду по логике графа.\n",
    "Например, сначала LLM-нода (gather_data_node) задаёт вопрос, ответ пользователя записывается в state.messages. Затем инструментальная нода (tool_node) может выполнить поиск, сохранить результат в state.tool_results, а потом снова передать управление LLM, которая уже учитывает новый результат.\n",
    "Это обеспечивает:\n",
    "Целостность процесса — всё сохраняется в одном месте;\n",
    "Гибкость — можно настраивать state под любую задачу;\n",
    "Повторное использование — состояние можно сохранить, экспортировать или использовать в логике ветвления (условных переходов).\n",
    "Таким образом, state — это не просто контейнер, а главный носитель контекста, обеспечивающий автономность, память и логику поведения ИИ-агента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0198adcb-44b7-4d56-a4a1-f2528b824b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e1430-3ec3-4ed0-9562-e9d0fdfca78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что лучше всего описывает подход RAG (Retrieval-Augmented Generation)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b46d3e-6ffe-4fd0-b158-700dcd59fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Использование нейросети для генерации изображений\n",
    "Генерация текста на основе примеров в промпте\n",
    "Обучение модели на пользовательских действиях в среде\n",
    "Использование поиска в базе знаний перед генерацией ответа  #\n",
    "Обучение модели с нуля на новых данных\n",
    "Преобразование текста в структурированные таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d323c-e738-4fef-8db6-f85011318ee6",
   "metadata": {},
   "source": [
    "RAG сочетает генеративную модель с поисковым компонентом. Сначала осуществляется поиск по внешней базе знаний, затем LLM генерирует ответ, используя найденную информацию. Это позволяет получать более точные и свежие ответы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324bad38-b99a-4b0f-96a7-5f7402218904",
   "metadata": {},
   "source": [
    "Retrieval-Augmented Generation (RAG) — это метод, в котором большая языковая модель (LLM) не полагается только на свою \"память\", полученную в ходе обучения. Вместо этого она сначала делает запрос в внешнюю базу знаний или поисковый движок (например, векторную базу данных или Google), чтобы получить актуальные документы или статьи, а затем использует эти данные как контекст для генерации ответа.\n",
    "Такой подход особенно полезен, когда:\n",
    "Нужно отвечать на вопросы по данным, которых нет в тренировочном корпусе модели.\n",
    "Требуется объяснение с цитатами из источников.\n",
    "Информация часто обновляется (например, законы, инструкции, цены). RAG уменьшает \"галлюцинации\" модели и делает ответы точнее, особенно в деловых, юридических и научных задачах. Это основа для построения агентов с доступом к реальному знанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661aa84a-986d-42c9-a302-0ff8e619cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f509f44-1f41-45ba-9cf9-3b819bf6d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Что из следующего лучше всего описывает подход Few-shot Learning в контексте LLM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffde787-c809-4d62-bf4f-6035534c8ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Обучение модели с нуля на огромном датасете\n",
    "Настройка LLM через Reinforcement Learning\n",
    "Генерация ответов без каких-либо примеров\n",
    "Передача модели нескольких примеров задачи прямо в запросе (prompt) #\n",
    "Постоянное обновление параметров модели на основе пользовательских запросов\n",
    "Поиск релевантных документов в базе знаний перед генерацией"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a841a-9be5-418e-b300-7d6184884d7c",
   "metadata": {},
   "source": [
    "Few-shot learning позволяет модели решать задачу, даже если в запрос передаётся всего несколько примеров. Это помогает модели понять формат или структуру задачи, без дополнительного обучения.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdcadaa-ca76-4a35-a1bc-f1a396f624cf",
   "metadata": {},
   "source": [
    "Few-shot Learning — это подход, при котором языковой модели (например, GPT-4) не требуется дополнительное обучение (fine-tuning) на новой задаче. Вместо этого ей дают несколько примеров прямо в тексте запроса — в промпте. Это и называется \"few shots\" — то есть \"несколько попыток\" или \"примеров\". few-shot: она \"обучается\" на лету, по нескольким примерам.\n",
    "Few-shot обучением часто называют также in-context learning — обучение внутри контекста.\n",
    "Главные преимущества:\n",
    "Не требует долгой и дорогой настройки модели.\n",
    "Подходит для задач, где есть ограниченное количество примеров.\n",
    "Гибкий: можно использовать разные стили, форматы, языки.\n",
    "Ограничения:\n",
    "Модель \"забывает\" эти примеры после завершения диалога.\n",
    "Эффективность зависит от качества примеров и длины промпта.\n",
    "Сложные задачи с нюансами могут потребовать более мощных техник (например, RAG или fine-tuning). Few-shot лежит в основе многих современных AI-агентов. Он позволяет им быстро адаптироваться к новым ситуациям и пользователям, особенно в интерфейсах без постоянной памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d5de27-6351-4f21-a44b-450bb173a338",
   "metadata": {},
   "source": [
    "few-shot learning напрямую связано с ИИ-агентами, особенно с теми, которые построены на базе больших языковых моделей (LLM), таких как GPT-4.\n",
    "\n",
    "Вот как это объясняется в контексте агентов:\n",
    "\n",
    "🧠 Зачем агенту few-shot learning?\n",
    "ИИ-агент — это не просто LLM. Это система, которая выполняет действия, принимает решения, использует инструменты (например, поиск или ввод от пользователя) и может адаптироваться к задачам. Но сама LLM, которая лежит в основе агента, часто не переобучается на каждую задачу. Вместо этого:\n",
    "\n",
    "➡️ Ей дают пару примеров в системном промпте или в первой ноде графа LangGraph.\n",
    "➡️ Это позволяет LLM понять, что нужно делать, без дообучения.  Примеры использования few-shot в агентах:\n",
    "🔹 Агент-юрист получает примеры, как оформлять жалобы.\n",
    "\n",
    "🔹 Агент-помощник по техподдержке видит пару примеров «вопрос → ответ» и продолжает по шаблону.\n",
    "\n",
    "🔹 Агент, запрашивающий паспортные данные, обучается прямо в промпте на том, как их правильно уточнять. Связь с LangGraph:\n",
    "В LangGraph, когда мы передаём system_prompt для ноды с LLM, туда можно встроить few-shot — и это критически важно для поведения агента. Если кратко:\n",
    "👉 Few-shot learning = способ \"воспитывать\" агента без переобучения.\n",
    "👉 Это важный метод, особенно на ранних стадиях построения agenta и тестирования его поведения. Он будет:\n",
    "\n",
    "Понимать структуру задачи.\n",
    "\n",
    "Отвечать в нужном формате.\n",
    "\n",
    "Вызывать нужные инструменты с нужными аргументами.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af58b330-84c1-4629-a168-bd5382072723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb54819d-a79e-4f2c-a563-e0fdf2c92002",
   "metadata": {},
   "outputs": [],
   "source": [
    "Какую ключевую роль играет Reinforcement Learning (RL) в обучении ИИ-агента?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e928686-2ee7-47df-ba6f-1cf777c2ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Позволяет агенту получать информацию с веб-сайтов\n",
    "Даёт агенту возможность хранить сообщения в памяти\n",
    "Обеспечивает обучение агента через вознаграждение за действия  #\n",
    "Преобразует текстовые данные в структурированный формат\n",
    "Используется для создания графа из нод и переходов\n",
    "Позволяет агенту использовать системный промпт"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829785ce-0ffe-4dc4-a0e4-4334ebece4a5",
   "metadata": {},
   "source": [
    "Reinforcement Learning — это метод обучения, в котором агент действует в среде, получает обратную связь (награду или штраф) и таким образом учится принимать лучшие решения для достижения цели."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e6d438d-3739-4a8a-a5d6-dc6a2625ba11",
   "metadata": {},
   "source": [
    "Reinforcement Learning (RL), или обучение с подкреплением, — это один из ключевых подходов в обучении ИИ-агентов, особенно когда речь идёт о принятии решений в интерактивной среде. В отличие от классического машинного обучения, где модель обучается на фиксированном наборе данных, в RL агент изучает поведение через опыт, взаимодействуя с окружающей средой.\n",
    "Каждое действие, совершаемое агентом, приводит к изменению состояния среды и сопровождается вознаграждением (reward) — числовой оценкой, которая говорит, насколько полезным было это действие. Цель агента — максимизировать суммарное вознаграждение со временем, то есть научиться стратегии, ведущей к лучшим результатам.\n",
    "В контексте ИИ-агентов, таких как те, что работают в LangGraph или LangChain, RL особенно полезен для настройки поведения агента в сложных задачах, где нужно оценивать, какое действие более разумно: например, когда запускать инструмент, когда задавать вопрос пользователю, а когда завершать работу. Вместо ручной настройки логики переходов, агент может научиться делать это самостоятельно, на основе опыта.Многие современные агенты используют RLHF (Reinforcement Learning with Human Feedback) — подход, при котором агенты обучаются с учётом оценок от человека, например, когда ответы ранжируются по качеству. Этот подход использовался при обучении ChatGPT.\n",
    "Таким образом, RL позволяет сделать агента более \"интеллектуальным\", научив его принимать решения, адаптируясь к изменяющимся условиям среды и поведению пользователя, что критически важно для создания надёжных и эффективных мультиагентных систем.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4d2de0-4c2f-4561-ba6d-30dfac25b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2069639-ab62-4b72-be81-778a976166c2",
   "metadata": {},
   "source": [
    "Что из этого лучше всего описывает метод RAG (Retrieval-Augmented Generation) в работе ИИ-агентов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bfa02f-9f3a-40ba-8648-2dfdb78caa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Обучение агента через награды и штрафы\n",
    "Метод сжатия текста для экономии токенов\n",
    "Использование внешних данных при генерации ответа #\n",
    "Тренировка агента на изображениях и звуке\n",
    "Автоматическое добавление промптов в tool_call\n",
    "Генерация ответов с использованием только встроенных знаний LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a134bfce-68e9-4b84-8e25-761eba5c6f64",
   "metadata": {},
   "source": [
    "RAG — это подход, при котором ИИ-агент обращается к внешним источникам (например, базе знаний), извлекает оттуда релевантную информацию и использует её для генерации более точного и информированного ответа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d959674-3dca-474f-b5bd-b37edd7346f2",
   "metadata": {},
   "source": [
    "Retrieval-Augmented Generation (RAG) — это архитектура, объединяющая генеративные возможности языковых моделей с поиском по внешним источникам знаний. Это особенно важно в случае, когда задача требует информации, которую модель не может \"помнить\" из-за ограничений её обучения или объёма входных данных.\n",
    "В классических LLM (таких как GPT) знание фиксировано на момент тренировки, и оно может устареть. RAG решает эту проблему, дополняя модель актуальной и специфической информацией, которую она получает на лету. Обычно это реализуется следующим образом:Пользователь задаёт вопрос.\n",
    "Агент формирует поисковый запрос и обращается к базе (например, внутренней векторной БД, Pinecone, FAISS или просто поисковой системе).\n",
    "Извлекается несколько релевантных документов (чаще всего в виде эмбеддингов или plain text).\n",
    "Эти документы добавляются к prompt’у, который подаётся в LLM.\n",
    "LLM использует и внутренние знания, и retrieved-документы для формирования ответа.\n",
    "Для ИИ-агентов это критически важно: при помощи RAG они могут:\n",
    "давать точные ответы на специфические вопросы (например, по внутренним документам компании),\n",
    "быть в курсе событий (если подключены к актуальным базам),\n",
    "уменьшать галлюцинации, ссылаясь на конкретные данные. Пример: агент-юрист, как в твоём кейсе, может с помощью RAG обращаться к базе законов и прецедентов, чтобы включать выдержки прямо в ответ.\n",
    "RAG не требует дообучения модели и работает \"на лету\", делая агента более гибким и адаптивным. Это один из ключевых шагов к созданию надежных и обоснованных ИИ-агентов, особенно в бизнесе и юридической сфере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85f4f6e-35be-4166-86c8-b94b26ad79f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a9a834-e31a-4b81-816c-8f9bba44c063",
   "metadata": {},
   "source": [
    "🔄 Что можно ДОБАВИТЬ:\n",
    "6. Механизмы завершения работы агента\n",
    "is_complete: как агент решает, что задача выполнена\n",
    "\n",
    "Как встроить проверку завершённости в граф\n",
    "\n",
    "Потенциальные ошибки, если завершение преждевременное\n",
    "\n",
    "7. Ошибки и отладка\n",
    "Как понимать ошибки в tool_call\n",
    "\n",
    "Что делать, если инструмент ничего не вернул\n",
    "\n",
    "Как логировать работу агента\n",
    "\n",
    "8. Модульность и переиспользование\n",
    "Как делать переиспользуемые подграфы\n",
    "\n",
    "Модульная архитектура агентов (внутри LangGraph / CrewAI) 9. Безопасность и доверие\n",
    "Когда агенту нельзя доверять\n",
    "\n",
    "Валидация данных, проверка гипотез\n",
    "\n",
    "Ограничения доступа (например, к WebSearch, human tools)\n",
    "\n",
    "10. Интеграция с внешними системами\n",
    "Как агент общается с API\n",
    "\n",
    "Использование LangChain tools как обёрток над API\n",
    "\n",
    "Реализация бизнес-процессов: CRM, базы данных, Google Sheets\n",
    "\n",
    "11. Контроль потока (Flow Control)\n",
    "Условные переходы в LangGraph (add_conditional_edges)\n",
    "\n",
    "Параллельные вызовы инструментов (multitool agents)\n",
    "\n",
    "Таймеры, retries и ограничения глубины вызова 12. Агенты со специальной логикой\n",
    "Code agents (сбор данных + генерация кода)\n",
    "\n",
    "Legal agents (как в твоём примере)\n",
    "\n",
    "Agents for documentation / chatbots / UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb1b5f2-da1b-47c1-8914-e9e4a7fe5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26037c8-9d89-4fb0-ac3a-eadd7f046def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62834bc-adc0-4448-9d11-0fb7cf898835",
   "metadata": {},
   "outputs": [],
   "source": [
    "Если говорить об ИИ-агентах на Python, то самая важная библиотека сейчас — это LangChain.\n",
    "\n",
    "Вот почему:\n",
    "\n",
    "✅ Почему LangChain — основа:\n",
    "Центральный фреймворк для создания ИИ-агентов.\n",
    "\n",
    "Объединяет LLM (например, ChatGPT), инструменты (tools), память (memory), и цепочки (chains) в единый рабочий процесс.\n",
    "\n",
    "Поддерживает все основные компоненты агента:\n",
    "\n",
    "Tool calls\n",
    "\n",
    "Memory\n",
    "\n",
    "Prompt templates\n",
    "\n",
    "Agents (React, OpenAI functions, LangGraph)\n",
    "\n",
    "Output parsing\n",
    "\n",
    "Имеет огромное сообщество и активную разработку.\n",
    "\n",
    "Поддерживает интеграции с LangGraph, LlamaIndex, OpenAI, Hugging Face и др.\n",
    "\n",
    "📊 Остальные библиотеки:\n",
    "Библиотека\tРоль\tКогда использовать\n",
    "LangGraph\tСтроит граф состояний (workflow)\tКогда нужен повторяющийся или контролируемый цикл работы агента\n",
    "LlamaIndex\tДоступ к внешним данным\tДля построения систем RAG (документы, базы, сайты)\n",
    "CrewAI\tМультиагентные сценарии\tКогда нужно несколько агентов с разными ролями\n",
    "\n",
    "🏆 Вывод:\n",
    "LangChain — самая важная, потому что она \"скелет\" всей экосистемы.\n",
    "Остальные надстраиваются сверху:\n",
    "\n",
    "LangGraph для контроля процесса,\n",
    "\n",
    "LlamaIndex для подключения данных,\n",
    "\n",
    "CrewAI для командной работы агентов.\n",
    "\n",
    "Если хочешь освоить всё с нуля — начни с LangChain.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73815685-3791-437e-b6e6-8ad8e06ca08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://python.langchain.com/docs/introduction/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
